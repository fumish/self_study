{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with laplace prior\n",
    " + In general, laplace prior gives sparse result for regression\n",
    "     + However, it is difficult to deal with it well due to non-differential point at the origin.\n",
    "         + $\\log p(w) \\equiv -1/\\beta \\sum_j |w_j| $, $|w_j|$ is non-differential at the origin.\n",
    " + By the way, non-differential point is eliminated by integrating $|w_j|$:\n",
    "     + $E[|w_j|]$ does not have non-diffenrential point when the distribution is normal distribution.\n",
    "     + It is achieved when we consider about the objective function of variational Bayes.\n",
    "         + $\\mathcal{F} := E[\\log \\frac{q(w)}{p(Y|X,w}p(w)]$\n",
    "         + Here, $\\mathcal{F}$ has a parameter that decides the form of $q(w) = N(w|m, \\Sigma)$, $(m, \\Sigma)$ is the parameter and optimized by it.\n",
    " + In this notebook, the approximated posterior distribution by Variational Bayes is studied.\n",
    "     + The objective function is optimized by a gradient descent method.\n",
    "         + Specifically, the Natural gradient descent is efficient method when we consider about a constrained parameter like positive definite matrix, positive real value, simplex, and so on.\n",
    "         + Thus, we used the natural gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation\n",
    "+ Learning Model:\n",
    "    + $p(y|x,w) = N(y|x \\cdot w, 1), y \\in mathbb{R}, x,w \\in \\mathbb{R}^M$\n",
    "    + $p(w) \\equiv \\exp(-\\frac{1}{\\beta} \\sum_j |w_j|)$, $\\beta$ is hyperparameter.\n",
    "+ Approximated Variational Posterior distribution:\n",
    "    + $q(w) = N(w|m, \\Sigma)$\n",
    "        + $m \\in \\mathbb{R}^M, \\Sigma \\in \\mathbb{R}^{M \\times M}$ is the parameters to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "+ We compare the following average generalization error:\n",
    "$$\n",
    "    G(n) = \\frac{1}{L} \\sum_{j=1}^L \\| y - X \\hat{w}(x^l, y^l) \\|^2,\n",
    "$$\n",
    "where $\\hat{w}$ is estimated parameter by $(x^l, y^l)$.  \n",
    "We evaluate the error among Lasso, Ridge, and VB laplace(this calculation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary\n",
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import invwishart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso, LassoLarsCV\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setting\n",
    "n = 500 # train size\n",
    "M = 1500 # # of features\n",
    "n_zero_ind = M // 4 * 3 # # of zero elements in the parameter\n",
    "prob_seed = 20201110 # random seed\n",
    "\n",
    "N = 10000 # test size\n",
    "\n",
    "datasets = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(prob_seed)\n",
    "true_w = np.random.normal(scale = 3, size = M)\n",
    "zero_ind = np.random.choice(M, size = n_zero_ind)\n",
    "true_w[zero_ind] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_vb_params = {\n",
    "    \"pri_beta\": 10,\n",
    "    \"pri_opt_flag\": True,\n",
    "    \"iteration\": 10000,\n",
    "    \"step\": 0.2,\n",
    "    \"is_trace\": False,\n",
    "    \"trace_step\": 100\n",
    "}\n",
    "ln_lasso_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5,\n",
    "    \"max_iter\": 10000\n",
    "}\n",
    "ln_ridge_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBLaplace(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        sq_sigma_diag = np.sqrt(np.diag(sigma))\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from laplace prior\n",
    "        F += ((mean + 2*sq_sigma_diag*norm.pdf(-mean/sq_sigma_diag)-2*mean*norm.cdf(-mean/sq_sigma_diag))/pri_beta).sum()\n",
    "\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "        \n",
    "        # transformation to natural parameter\n",
    "        theta1 = np.linalg.solve(est_sigma, est_mean)\n",
    "        theta2 = -np.linalg.inv(est_sigma)/2        \n",
    "        \n",
    "        F = []\n",
    "        \n",
    "        cov_X = train_X.T @ train_X\n",
    "        cov_YX = train_Y @ train_X\n",
    "        for ite in range(iteration):\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "\n",
    "            # update mean and sigma by natural gradient\n",
    "            dFdnu1 = theta1 - cov_YX\n",
    "            dFdnu1 += (1 - 2*est_mean/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag) - 2*norm.cdf(-est_mean/sq_sigma_diag)) / est_pri_beta\n",
    "            dFdnu2 = theta2 + cov_X/2\n",
    "            dFdnu2[np.diag_indices(M)] += 1/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)/est_pri_beta\n",
    "\n",
    "            theta1 += -step * dFdnu1\n",
    "            theta2 += -step * dFdnu2\n",
    "            est_sigma = -np.linalg.inv(theta2)/2\n",
    "            est_mean = est_sigma @ theta1\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "            est_pri_beta = ((est_mean + 2*sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)-2*est_mean*norm.cdf(-est_mean/sq_sigma_diag))).mean() if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBNormal(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from Normal prior\n",
    "        F += pri_beta/2*(mean@mean + np.trace(sigma)) - M/2*np.log(pri_beta) + M/2*log_2pi\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        XY_cov = train_Y@train_X\n",
    "        X_cov = train_X.T@train_X\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            sigma_inv = X_cov + est_pri_beta*np.eye(M)\n",
    "            est_mean = np.linalg.solve(sigma_inv, XY_cov)\n",
    "            est_sigma = np.linalg.inv(sigma_inv)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/(est_mean@est_mean + np.trace(est_sigma)) if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBApproxLaplace(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Laplace prior is approximated by normal distribution, and approximated posterior distribution is obtained by the approximated laplace prior.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, y:np.ndarray, pri_beta:float, mean:np.ndarray, inv_sigma:np.ndarray, h_xi: np.ndarray, v_xi: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        F = 0\n",
    "        F += pri_beta/2*np.sqrt(h_xi).sum() + v_xi@h_xi - M*np.log(pri_beta/2)\n",
    "        F += n/2*np.log(2*np.pi) + train_Y@train_Y/2 - mean @ (inv_sigma @ mean)/2 + np.linalg.slogdet(inv_sigma)[0]/2\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        X_cov = train_X.T@train_X\n",
    "        XY_cov = train_X.T @ train_Y\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            # update form of approximated laplace prior\n",
    "            est_h_xi = est_mean**2 + np.diag(est_sigma)\n",
    "            est_v_xi = -est_pri_beta/2/np.sqrt(est_h_xi)            \n",
    "            \n",
    "            # update posterior distribution\n",
    "            inv_sigma = X_cov -2*np.diag(est_v_xi)\n",
    "            est_mean = np.linalg.solve(inv_sigma, XY_cov)\n",
    "            est_sigma = np.linalg.inv(inv_sigma)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/((est_mean**2 + np.diag(est_sigma))/(2*np.sqrt(est_h_xi))).sum() if self.pri_opt_flag else pri_beta\n",
    "            \n",
    "            current_F = self._obj_func(train_Y, est_pri_beta, est_mean, inv_sigma, est_h_xi, est_v_xi)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F)            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment part\n",
    "+ By some datasets are used for train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4534.311991090998 4075.4814729137124 3787.090488046122 4074.8316157436548 3934.960720145028\n",
      "4429.190577525712 4208.1193711598025 3877.4592353186117 4207.1948723490705 3935.049306520366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2899ffdda7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mvb_laplace_exact_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mvb_normal_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mvb_laplace_approx_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7a1b86589538>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_X, train_Y)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;31m# update posterior distribution\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0minv_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_cov\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest_v_xi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_sigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXY_cov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0mest_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_sigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'DD->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'dd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sq_error_vb_laplace_exact = np.zeros(datasets)\n",
    "sq_error_vb_laplace_approx = np.zeros(datasets)\n",
    "sq_error_vb_normal = np.zeros(datasets)\n",
    "sq_error_lasso = np.zeros(datasets)\n",
    "sq_error_ridge = np.zeros(datasets)\n",
    "\n",
    "for dataset_ind in range(datasets):\n",
    "    vb_laplace_exact_obj = VBLaplace(**ln_vb_params)\n",
    "    vb_laplace_approx_obj = VBApproxLaplace(**ln_vb_params)\n",
    "    vb_normal_obj = VBNormal(**ln_vb_params)\n",
    "    lasso_obj = LassoCV(**ln_lasso_params)\n",
    "    ridge_obj = RidgeCV(**ln_ridge_params)    \n",
    "    \n",
    "    # data generation\n",
    "    train_X = np.random.normal(size = (n, M))\n",
    "    train_Y = train_X @ true_w + np.random.normal(size = n)\n",
    "\n",
    "    lasso_obj.fit(train_X, train_Y)\n",
    "    ridge_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_exact_obj.fit(train_X, train_Y)\n",
    "    vb_normal_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_approx_obj.fit(train_X, train_Y)\n",
    "\n",
    "    test_X = np.random.normal(size = (N, M))\n",
    "    test_Y = test_X @ true_w + np.random.normal(size = N)\n",
    "    \n",
    "    sq_error_lasso[dataset_ind] = ((test_X @ lasso_obj.coef_- test_Y)**2).mean()\n",
    "    sq_error_ridge[dataset_ind] = ((test_X @ ridge_obj.coef_- test_Y)**2).mean()\n",
    "    sq_error_vb_laplace_exact[dataset_ind] = ((test_X @ vb_laplace_exact_obj.mean_- test_Y)**2).mean()\n",
    "    sq_error_vb_normal[dataset_ind] = ((test_X @ vb_normal_obj.mean_- test_Y)**2).mean()\n",
    "    sq_error_vb_laplace_approx[dataset_ind] = ((test_X @ vb_laplace_approx_obj.mean_- test_Y)**2).mean()\n",
    "    print(\n",
    "        sq_error_lasso[dataset_ind]\n",
    "        , sq_error_ridge[dataset_ind]\n",
    "        , sq_error_vb_laplace_exact[dataset_ind]\n",
    "        , sq_error_vb_normal[dataset_ind]\n",
    "        , sq_error_vb_laplace_approx[dataset_ind]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987.1187289749577 822.3076558971542 775.5329864451683 821.5454934882786 819.4350952460704\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sq_error_lasso.mean()\n",
    "    , sq_error_ridge.mean()\n",
    "    , sq_error_vb_laplace_exact.mean()\n",
    "    , sq_error_vb_normal.mean()\n",
    "    , sq_error_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_lasso)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_vb_laplace_exact)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_vb_normal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.10485992387093"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_error_lasso.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , -0.76668197,\n",
       "        0.07758316,  0.        , -0.0995576 ,  0.        , -0.90644613,\n",
       "        0.        ,  0.        , -1.16645995,  1.00565264, -1.27819984,\n",
       "        0.30094245, -0.627204  ,  3.38047157,  1.22344481,  0.0473449 ,\n",
       "       -0.03814966,  0.        ,  0.        ,  3.52029545,  0.        ,\n",
       "        4.81596502,  0.        , -3.25347577,  0.66002526,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.63380714,  1.33677451,\n",
       "        0.        , -2.69622796,  3.58475763,  0.        ,  0.        ,\n",
       "        2.71306942,  0.        ,  1.88162727, -2.59235379,  3.48865255,\n",
       "        0.        ,  0.        ,  0.        ,  2.00792993, -0.4410573 ,\n",
       "        0.        , -4.15620415,  3.9016001 ,  0.        ,  6.5176337 ,\n",
       "       -3.96303101, -0.03691128,  1.35713552,  2.36783035,  0.        ,\n",
       "        0.        ,  0.18762913, -1.26910508, -3.83069906,  0.26426108,\n",
       "       -1.0842188 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        2.82239462,  0.16265215,  0.        ,  0.        ,  0.        ,\n",
       "        1.42660064, -0.55960312, -1.35619478, -5.20937925,  0.        ,\n",
       "       -0.97513867,  0.        ,  5.61036017, -2.75649377, -4.37142083,\n",
       "        0.6528961 ,  3.65665585,  4.40974135, -0.18317878, -3.07988735,\n",
       "        0.        , -2.53854171,  3.27560309,  0.        ,  7.81317023,\n",
       "        0.        ,  0.        ,  0.        , -4.21542812,  0.        ,\n",
       "       -5.32304818,  0.        ,  0.        ,  1.46339651, -2.80157424,\n",
       "        2.40381311,  1.93661268,  0.        , -3.68530166,  3.68187137,\n",
       "        4.6779508 ,  1.30380009,  0.        ,  0.17820812,  0.        ,\n",
       "       -4.04242208,  0.        ,  0.        ,  0.        , -1.69246901,\n",
       "        1.35555417,  2.7963506 ,  0.        ,  3.07879094, -3.43986175,\n",
       "       -5.22595885,  0.39853712,  3.12602451, -4.18756991,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  4.31956641,\n",
       "       -1.51861904, -4.10136198,  0.30293722,  0.        ,  0.        ,\n",
       "        0.        , -0.21288762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.77619219,  3.10719351,\n",
       "       -2.62922584,  1.34767249,  1.17694762,  0.        ,  0.82839278,\n",
       "        0.        , -2.43049864, -4.70204062,  0.31933329,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.37294018,\n",
       "        0.        ,  0.49227329,  1.88058534, -2.15501367,  0.        ,\n",
       "        2.51412901, -2.62329196,  1.88505711,  0.        , -1.44365597,\n",
       "        0.        , -5.9506191 ,  4.61010472, -0.3914984 , -2.56273853,\n",
       "        0.        ,  0.        , -0.03003618,  2.00666083, -1.11247555,\n",
       "        5.80470762, -0.75163024, -0.23380517,  0.67443324,  1.1577714 ,\n",
       "       -1.46410966,  0.        , -3.65760862, -1.67716493, -2.42723579,\n",
       "        0.        , -1.72682638, -0.84503449, -0.45390357,  0.        ,\n",
       "        0.        ,  0.        , -3.61775795, -1.11710953,  3.11547965,\n",
       "       -3.40428624,  1.72675508,  0.        , -1.09670842,  2.21402638,\n",
       "        0.        ,  5.68384374, 10.00605115,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -4.4211814 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.12343038,  0.        ,  0.18522035,\n",
       "       -1.45337341,  0.        ,  2.88056761,  0.47835039,  1.22293896,\n",
       "        6.02282615, -0.55582293,  2.80719361, -9.04599777,  1.31709791,\n",
       "        0.        ,  1.41886036, -2.11526084,  1.31447898,  0.        ,\n",
       "       -1.88083653, -1.16022406,  0.        ,  0.        , -3.53824703,\n",
       "       -0.63372719,  0.        , -6.38107692,  5.22173563, -1.72092071,\n",
       "        1.34919695,  3.33451544,  2.68218189,  0.        , -9.42245829,\n",
       "        4.31844858,  0.        , -0.27071409, -1.75983284,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.71381013,\n",
       "       -4.36134198,  0.        ,  2.86892206,  4.43305466,  0.        ,\n",
       "        0.        ,  3.6775742 ,  0.        ,  0.        ,  0.        ,\n",
       "        1.08341558, -3.30639853,  2.06305632,  0.33057913,  0.19251094,\n",
       "        0.        ,  0.        , -0.88649413,  0.93654874, -0.92907885,\n",
       "        0.        ,  1.98561399,  0.        , -6.21216341, -1.44129124,\n",
       "        0.        , -2.44364738,  0.        ,  0.        , -4.60931771,\n",
       "        0.        , -7.1060601 , -0.25450493,  3.80237406, -1.03990865,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.50845406,\n",
       "        1.43603562,  0.        , -1.20824397,  0.34298881,  0.        ,\n",
       "       -0.10126385,  2.32899934,  0.        ,  0.        ,  2.53418494,\n",
       "        1.09601969, -1.3079937 , -1.43857833,  1.69509419,  0.        ,\n",
       "       -0.32535721,  1.34677404,  0.        ,  1.6209045 ,  0.        ,\n",
       "        0.37218781,  0.10660404, -2.18739269, -0.21103329,  3.88906184,\n",
       "        0.14417489, -0.44632924,  0.        , -3.08581264,  0.        ,\n",
       "       -0.64647768,  0.        ,  0.        ,  0.        ,  3.45132807,\n",
       "       -5.00554243, -0.69960904, -1.49639685,  0.        ,  0.        ,\n",
       "        0.        ,  0.82544241, -1.59146572,  2.98871443,  3.62286903,\n",
       "        1.42762964,  0.        ,  0.        ,  2.47423043,  0.        ,\n",
       "        0.        , -3.93509534, -3.67117534, -1.66381531,  1.56373128,\n",
       "       -2.54003703,  1.59270721,  0.        , -3.34179223,  0.        ,\n",
       "        1.65598468, -0.63192153,  3.2586072 ,  3.79248979,  1.8805576 ,\n",
       "        0.        ,  0.        ,  0.67639555,  2.12813618,  0.        ,\n",
       "       -2.03734815, -0.92737418, -0.76446219,  0.26149847, -1.01734604,\n",
       "        0.        ,  0.        ,  0.        ,  2.90633058, -1.7841167 ,\n",
       "        0.        ,  2.43839142,  1.72382498,  0.91379309, -4.73625657,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.76208384,\n",
       "       -5.52170122, -5.29286887,  3.40864884,  1.99232504,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.62730881,  0.        ,\n",
       "        0.        , -2.27439354,  0.4710198 ,  0.        ,  2.47498796,\n",
       "        0.        , -0.08208131, -4.96373925, -0.44566027,  0.        ,\n",
       "       -6.48977714,  0.        ,  0.        ,  2.27450145, -3.93815903,\n",
       "        3.3400167 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.463294  ,  0.        , -0.97093426,\n",
       "        0.        ,  2.09674151,  2.34015509,  0.        ,  2.04765046,\n",
       "        0.        ,  2.79378918, -3.53025833,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.34513262,  1.83249431,  0.        ,  2.75072664, -0.09395582,\n",
       "        0.        , -4.52339131,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.13120524, -1.74165902,  0.        ,  2.79691941,\n",
       "        2.63991594,  0.        ,  3.2993635 , -2.01361589,  2.02896249,\n",
       "        1.14511249, -0.30690699,  2.8638261 ,  0.        , -1.90000553,\n",
       "        2.10753598,  1.25927173, -2.0796748 ,  0.        ,  0.8230681 ,\n",
       "        2.19885118,  2.00914115,  8.62446715,  0.        , -1.25440593,\n",
       "        2.36717472,  1.67806024,  0.45576057,  0.        ,  2.94290434,\n",
       "       -6.67368945,  4.84287936,  0.        , -1.54032161,  0.        ,\n",
       "       -1.45007199,  0.        ,  0.        ,  0.14619982,  1.24542242,\n",
       "       -1.1466085 ,  0.        ,  0.        , -0.87419234,  4.46233691,\n",
       "       -1.71233723, -5.01433667,  2.26989479,  3.50090393,  0.        ,\n",
       "        1.14726699,  0.        , -6.01328696,  1.50616649,  0.        ,\n",
       "        1.71264187,  0.        ,  1.61466992,  0.43339527,  0.        ,\n",
       "        0.        ,  0.04176741, -2.46692818, -1.69221917,  0.        ,\n",
       "        4.96165716,  5.70358511,  0.        ,  1.64405708,  3.47260936,\n",
       "       -4.14704621,  1.13520012,  4.72538745,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.72411832,  2.05994544,\n",
       "       -2.04054909, -5.93196356,  0.        , -6.38319172,  2.66130388,\n",
       "        0.54021669,  2.11793369, -5.40525212,  1.69551788,  0.        ,\n",
       "        0.        ,  1.63502311, -0.87789452, -1.26780838,  0.        ,\n",
       "       -1.69376272,  1.42150321,  0.75101169,  1.70050797,  0.        ,\n",
       "        6.76881923,  0.        , -1.72645458, -0.34222196,  0.        ,\n",
       "        0.        ,  0.        ,  4.20692684, -1.49838649, -0.42849111,\n",
       "        3.27441965,  0.        ,  0.        ,  1.33915726, -2.84127863,\n",
       "        0.        , -1.43255817,  0.        , -3.91065627,  0.        ,\n",
       "        3.28198124,  0.        ,  1.08150973, -0.74044771, -5.10018979,\n",
       "        0.98746237,  0.        ,  2.98754322, -3.93588581, -2.10669405,\n",
       "        0.        ,  0.        , -1.75450388,  0.80332304,  0.        ,\n",
       "        2.25687791,  0.        , -3.02195407, -0.34214784, -1.19599784,\n",
       "        0.        ,  0.        ,  1.20211888,  4.74596595, -3.36959436])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
