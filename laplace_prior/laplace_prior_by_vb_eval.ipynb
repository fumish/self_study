{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with laplace prior\n",
    " + In general, laplace prior gives sparse result for regression\n",
    "     + However, it is difficult to deal with it well due to non-differential point at the origin.\n",
    "         + $\\log p(w) \\equiv -1/\\beta \\sum_j |w_j| $, $|w_j|$ is non-differential at the origin.\n",
    " + By the way, non-differential point is eliminated by integrating $|w_j|$:\n",
    "     + $E[|w_j|]$ does not have non-diffenrential point when the distribution is normal distribution.\n",
    "     + It is achieved when we consider about the objective function of variational Bayes.\n",
    "         + $\\mathcal{F} := E[\\log \\frac{q(w)}{p(Y|X,w}p(w)]$\n",
    "         + Here, $\\mathcal{F}$ has a parameter that decides the form of $q(w) = N(w|m, \\Sigma)$, $(m, \\Sigma)$ is the parameter and optimized by it.\n",
    " + In this notebook, the approximated posterior distribution by Variational Bayes is studied.\n",
    "     + The objective function is optimized by a gradient descent method.\n",
    "         + Specifically, the Natural gradient descent is efficient method when we consider about a constrained parameter like positive definite matrix, positive real value, simplex, and so on.\n",
    "         + Thus, we used the natural gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation\n",
    "+ Learning Model:\n",
    "    + $p(y|x,w) = N(y|x \\cdot w, 1), y \\in mathbb{R}, x,w \\in \\mathbb{R}^M$\n",
    "    + $p(w) \\equiv \\exp(-\\frac{1}{\\beta} \\sum_j |w_j|)$, $\\beta$ is hyperparameter.\n",
    "+ Approximated Variational Posterior distribution:\n",
    "    + $q(w) = N(w|m, \\Sigma)$\n",
    "        + $m \\in \\mathbb{R}^M, \\Sigma \\in \\mathbb{R}^{M \\times M}$ is the parameters to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "+ We compare the following average generalization error:\n",
    "$$\n",
    "    G(n) = \\frac{1}{L} \\sum_{j=1}^L \\| y - X \\hat{w}(x^l, y^l) \\|^2,\n",
    "$$\n",
    "where $\\hat{w}$ is estimated parameter by $(x^l, y^l)$.  \n",
    "We evaluate the error among Lasso, Ridge, and VB laplace(this calculation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary\n",
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import invwishart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso, LassoLarsCV\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setting\n",
    "n = 500 # train size\n",
    "M = 1500 # # of features\n",
    "n_zero_ind = M // 4 * 3 # # of zero elements in the parameter\n",
    "prob_seed = 20201110 # random seed\n",
    "\n",
    "N = 10000 # test size\n",
    "\n",
    "datasets = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(prob_seed)\n",
    "true_w = np.random.normal(scale = 3, size = M)\n",
    "zero_ind = np.random.choice(M, size = n_zero_ind)\n",
    "true_w[zero_ind] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_vb_params = {\n",
    "    \"pri_beta\": 10,\n",
    "    \"pri_opt_flag\": True,\n",
    "    \"iteration\": 10000,\n",
    "    \"step\": 0.2,\n",
    "    \"is_trace\": False,\n",
    "    \"trace_step\": 100\n",
    "}\n",
    "ln_lasso_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5,\n",
    "    \"max_iter\": 10000\n",
    "}\n",
    "ln_ridge_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBLaplace(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        sq_sigma_diag = np.sqrt(np.diag(sigma))\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from laplace prior\n",
    "        F += ((mean + 2*sq_sigma_diag*norm.pdf(-mean/sq_sigma_diag)-2*mean*norm.cdf(-mean/sq_sigma_diag))/pri_beta).sum()\n",
    "\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "        \n",
    "        # transformation to natural parameter\n",
    "        theta1 = np.linalg.solve(est_sigma, est_mean)\n",
    "        theta2 = -np.linalg.inv(est_sigma)/2        \n",
    "        \n",
    "        F = []\n",
    "        \n",
    "        cov_X = train_X.T @ train_X\n",
    "        cov_YX = train_Y @ train_X\n",
    "        for ite in range(iteration):\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "\n",
    "            # update mean and sigma by natural gradient\n",
    "            dFdnu1 = theta1 - cov_YX\n",
    "            dFdnu1 += (1 - 2*est_mean/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag) - 2*norm.cdf(-est_mean/sq_sigma_diag)) / est_pri_beta\n",
    "            dFdnu2 = theta2 + cov_X/2\n",
    "            dFdnu2[np.diag_indices(M)] += 1/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)/est_pri_beta\n",
    "\n",
    "            theta1 += -step * dFdnu1\n",
    "            theta2 += -step * dFdnu2\n",
    "            est_sigma = -np.linalg.inv(theta2)/2\n",
    "            est_mean = est_sigma @ theta1\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "            est_pri_beta = ((est_mean + 2*sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)-2*est_mean*norm.cdf(-est_mean/sq_sigma_diag))).mean() if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBNormal(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from Normal prior\n",
    "        F += pri_beta/2*(mean@mean + np.trace(sigma)) - M/2*np.log(pri_beta) + M/2*log_2pi\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        XY_cov = train_Y@train_X\n",
    "        X_cov = train_X.T@train_X\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            sigma_inv = X_cov + est_pri_beta*np.eye(M)\n",
    "            est_mean = np.linalg.solve(sigma_inv, XY_cov)\n",
    "            est_sigma = np.linalg.inv(sigma_inv)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/(est_mean@est_mean + np.trace(est_sigma)) if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBApproxLaplace(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Laplace prior is approximated by normal distribution, and approximated posterior distribution is obtained by the approximated laplace prior.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, y:np.ndarray, pri_beta:float, mean:np.ndarray, inv_sigma:np.ndarray, h_xi: np.ndarray, v_xi: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        F = 0\n",
    "        F += pri_beta/2*np.sqrt(h_xi).sum() + v_xi@h_xi - M*np.log(pri_beta/2)\n",
    "        F += n/2*np.log(2*np.pi) + train_Y@train_Y/2 - mean @ (inv_sigma @ mean)/2 + np.linalg.slogdet(inv_sigma)[0]/2\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        X_cov = train_X.T@train_X\n",
    "        XY_cov = train_X.T @ train_Y\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            # update form of approximated laplace prior\n",
    "            est_h_xi = est_mean**2 + np.diag(est_sigma)\n",
    "            est_v_xi = -est_pri_beta/2/np.sqrt(est_h_xi)            \n",
    "            \n",
    "            # update posterior distribution\n",
    "            inv_sigma = X_cov -2*np.diag(est_v_xi)\n",
    "            est_mean = np.linalg.solve(inv_sigma, XY_cov)\n",
    "            est_sigma = np.linalg.inv(inv_sigma)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/((est_mean**2 + np.diag(est_sigma))/(2*np.sqrt(est_h_xi))).sum() if self.pri_opt_flag else pri_beta\n",
    "            \n",
    "            current_F = self._obj_func(train_Y, est_pri_beta, est_mean, inv_sigma, est_h_xi, est_v_xi)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F)            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment part\n",
    "+ By some datasets are used for train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4534.311991090998 4075.4814729137124 3787.090488049996 4074.831615744289 3934.9607198985964\n",
      "4429.190577525714 4208.1193711598025 3877.4592353126077 4207.194872348408 3935.0493056406217\n",
      "4517.152756175873 4144.5486834821195 3934.146850665892 4144.537917473443 4219.516742241699\n",
      "4832.417303789781 4154.091435690235 3997.6419846491563 4153.613699463033 4366.391836895246\n",
      "4899.6158574441015 4271.145227399941 3982.9267684898778 4271.1645378255 4104.851411020691\n",
      "5007.036005383226 3973.1684514652943 3644.9990883110167 3973.1707369413034 3728.9777932541965\n",
      "4981.97269253664 4155.333299982712 3891.445968329353 4155.336785196968 4160.550615059665\n",
      "4824.814616604173 3964.24440632008 3762.213201241725 3964.255862901935 4054.6980074114867\n",
      "4325.753160403825 4008.605895650634 3708.1456453838423 4008.6179438365943 3879.746389472306\n",
      "4618.668067112397 4222.7786682684855 3956.831147049704 4223.208361716816 4157.194125204899\n",
      "4583.316768012168 3998.785625885353 3748.1863336151005 3999.4065060550047 3910.604600455262\n",
      "4774.573659656746 4108.3091650286015 3777.08849833555 4108.053313876511 3997.565950692586\n",
      "4507.463283257848 3926.8516795500136 3657.346675705091 3926.8638131204225 3808.6018981769935\n",
      "4627.7645809291225 4040.9772505378505 3835.7464617332244 4040.9250271330798 4197.936941988983\n",
      "4119.20683611553 4089.7762268226847 3669.0765429173566 4089.7745095325186 3702.487740643227\n",
      "4348.412086878553 3867.889176078883 3658.3047802428246 3867.5668857603723 3949.256811005345\n",
      "4518.215858974932 4170.838342750733 3875.5788154654474 4170.841151151326 3999.4541523330427\n",
      "4581.733249015367 3836.990844390762 3558.0502023971103 3836.9887946794747 3711.3271823602236\n",
      "4721.329164088979 4099.434740842407 3915.358019016412 4099.431484518949 4234.313048921607\n",
      "5944.956950587791 4204.349759754817 3911.366456375782 4204.325250874005 3932.7218101284534\n",
      "5005.127111584411 4103.669472230932 3856.3487501905233 4103.684393064063 4110.04974390427\n",
      "4401.0534215523085 4052.741532361542 3745.006986343655 4053.7952987466797 3957.7198845697985\n",
      "4887.8746670688215 4412.411685890154 4203.581415759534 4413.217799298318 4434.7378244199235\n",
      "4630.503403179719 4175.445030285001 3970.746493784586 4175.660769750988 4150.039357409406\n",
      "4495.897467874245 4268.000019182692 4028.3706544750853 4268.046237686853 4170.417932515615\n",
      "4713.136356954897 4257.5149452213045 4067.9611530040092 4257.528296653084 4163.218743847492\n",
      "4875.027806606985 4233.040679131536 4033.374885689377 4233.054892094643 4350.413579249715\n",
      "4772.249139476825 4209.980670009555 3889.980103172839 4210.000625769873 4014.532617934385\n",
      "4033.1033480421042 3863.6135454067535 3518.762961304254 3863.606057860898 3577.901847835768\n",
      "4765.163504434824 4184.557341830329 3987.478219443135 4184.25597714408 4226.82704040131\n",
      "4628.608465511927 4075.5754559013353 3855.7902543539785 4074.9855133382925 4011.6382511983356\n",
      "4880.49159583078 4256.850619490993 3945.492980505074 4256.8318827559915 4012.186006196198\n",
      "5181.817638231423 4179.2501428541 4009.6724324119577 4179.251726446471 4143.4950709396535\n",
      "4790.090763008561 4190.59793727415 3985.899948184563 4190.574105603361 4302.130477301882\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2899ffdda7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mvb_laplace_exact_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mvb_normal_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mvb_laplace_approx_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7a1b86589538>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_X, train_Y)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mest_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-7a1b86589538>\u001b[0m in \u001b[0;36m_initialization\u001b[1;34m(self, M)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvwishart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mpri_beta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpri_opt_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpri_beta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36mrvs\u001b[1;34m(self, df, scale, size, random_state)\u001b[0m\n\u001b[0;32m   2779\u001b[0m         \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minv_scale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2781\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2783\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_squeeze_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36m_rvs\u001b[1;34m(self, n, shape, dim, df, C, random_state)\u001b[0m\n\u001b[0;32m   2734\u001b[0m             \u001b[1;31m# Get (C A)^{-1} via triangular solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2736\u001b[1;33m                 \u001b[0mCA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrtrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2737\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2738\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sq_error_vb_laplace_exact = np.zeros(datasets)\n",
    "sq_error_vb_laplace_approx = np.zeros(datasets)\n",
    "sq_error_vb_normal = np.zeros(datasets)\n",
    "sq_error_lasso = np.zeros(datasets)\n",
    "sq_error_ridge = np.zeros(datasets)\n",
    "\n",
    "for dataset_ind in range(datasets):\n",
    "    vb_laplace_exact_obj = VBLaplace(**ln_vb_params)\n",
    "    vb_laplace_approx_obj = VBApproxLaplace(**ln_vb_params)\n",
    "    vb_normal_obj = VBNormal(**ln_vb_params)\n",
    "    lasso_obj = LassoCV(**ln_lasso_params)\n",
    "    ridge_obj = RidgeCV(**ln_ridge_params)    \n",
    "    \n",
    "    # data generation\n",
    "    train_X = np.random.normal(size = (n, M))\n",
    "    train_Y = train_X @ true_w + np.random.normal(size = n)\n",
    "\n",
    "    lasso_obj.fit(train_X, train_Y)\n",
    "    ridge_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_exact_obj.fit(train_X, train_Y)\n",
    "    vb_normal_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_approx_obj.fit(train_X, train_Y)\n",
    "\n",
    "    test_X = np.random.normal(size = (N, M))\n",
    "    test_Y = test_X @ true_w + np.random.normal(size = N)\n",
    "    \n",
    "    sq_error_lasso[dataset_ind] = ((test_X @ lasso_obj.coef_- test_Y)**2).mean()\n",
    "    sq_error_ridge[dataset_ind] = ((test_X @ ridge_obj.coef_- test_Y)**2).mean()\n",
    "    sq_error_vb_laplace_exact[dataset_ind] = ((test_X @ vb_laplace_exact_obj.mean_- test_Y)**2).mean()\n",
    "    sq_error_vb_normal[dataset_ind] = ((test_X @ vb_normal_obj.mean_- test_Y)**2).mean()\n",
    "    sq_error_vb_laplace_approx[dataset_ind] = ((test_X @ vb_laplace_approx_obj.mean_- test_Y)**2).mean()\n",
    "    print(\n",
    "        sq_error_lasso[dataset_ind]\n",
    "        , sq_error_ridge[dataset_ind]\n",
    "        , sq_error_vb_laplace_exact[dataset_ind]\n",
    "        , sq_error_vb_normal[dataset_ind]\n",
    "        , sq_error_vb_laplace_approx[dataset_ind]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1597.5805015494159 1399.8496880104549 1312.4747040190964 1399.8460264636356 1376.1151546052888\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sq_error_lasso.mean()\n",
    "    , sq_error_ridge.mean()\n",
    "    , sq_error_vb_laplace_exact.mean()\n",
    "    , sq_error_vb_normal.mean()\n",
    "    , sq_error_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_lasso)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_vb_laplace_exact)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sq_error_vb_normal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.10485992387093"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_error_lasso.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , -0.76668197,\n",
       "        0.07758316,  0.        , -0.0995576 ,  0.        , -0.90644613,\n",
       "        0.        ,  0.        , -1.16645995,  1.00565264, -1.27819984,\n",
       "        0.30094245, -0.627204  ,  3.38047157,  1.22344481,  0.0473449 ,\n",
       "       -0.03814966,  0.        ,  0.        ,  3.52029545,  0.        ,\n",
       "        4.81596502,  0.        , -3.25347577,  0.66002526,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.63380714,  1.33677451,\n",
       "        0.        , -2.69622796,  3.58475763,  0.        ,  0.        ,\n",
       "        2.71306942,  0.        ,  1.88162727, -2.59235379,  3.48865255,\n",
       "        0.        ,  0.        ,  0.        ,  2.00792993, -0.4410573 ,\n",
       "        0.        , -4.15620415,  3.9016001 ,  0.        ,  6.5176337 ,\n",
       "       -3.96303101, -0.03691128,  1.35713552,  2.36783035,  0.        ,\n",
       "        0.        ,  0.18762913, -1.26910508, -3.83069906,  0.26426108,\n",
       "       -1.0842188 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        2.82239462,  0.16265215,  0.        ,  0.        ,  0.        ,\n",
       "        1.42660064, -0.55960312, -1.35619478, -5.20937925,  0.        ,\n",
       "       -0.97513867,  0.        ,  5.61036017, -2.75649377, -4.37142083,\n",
       "        0.6528961 ,  3.65665585,  4.40974135, -0.18317878, -3.07988735,\n",
       "        0.        , -2.53854171,  3.27560309,  0.        ,  7.81317023,\n",
       "        0.        ,  0.        ,  0.        , -4.21542812,  0.        ,\n",
       "       -5.32304818,  0.        ,  0.        ,  1.46339651, -2.80157424,\n",
       "        2.40381311,  1.93661268,  0.        , -3.68530166,  3.68187137,\n",
       "        4.6779508 ,  1.30380009,  0.        ,  0.17820812,  0.        ,\n",
       "       -4.04242208,  0.        ,  0.        ,  0.        , -1.69246901,\n",
       "        1.35555417,  2.7963506 ,  0.        ,  3.07879094, -3.43986175,\n",
       "       -5.22595885,  0.39853712,  3.12602451, -4.18756991,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  4.31956641,\n",
       "       -1.51861904, -4.10136198,  0.30293722,  0.        ,  0.        ,\n",
       "        0.        , -0.21288762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.77619219,  3.10719351,\n",
       "       -2.62922584,  1.34767249,  1.17694762,  0.        ,  0.82839278,\n",
       "        0.        , -2.43049864, -4.70204062,  0.31933329,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.37294018,\n",
       "        0.        ,  0.49227329,  1.88058534, -2.15501367,  0.        ,\n",
       "        2.51412901, -2.62329196,  1.88505711,  0.        , -1.44365597,\n",
       "        0.        , -5.9506191 ,  4.61010472, -0.3914984 , -2.56273853,\n",
       "        0.        ,  0.        , -0.03003618,  2.00666083, -1.11247555,\n",
       "        5.80470762, -0.75163024, -0.23380517,  0.67443324,  1.1577714 ,\n",
       "       -1.46410966,  0.        , -3.65760862, -1.67716493, -2.42723579,\n",
       "        0.        , -1.72682638, -0.84503449, -0.45390357,  0.        ,\n",
       "        0.        ,  0.        , -3.61775795, -1.11710953,  3.11547965,\n",
       "       -3.40428624,  1.72675508,  0.        , -1.09670842,  2.21402638,\n",
       "        0.        ,  5.68384374, 10.00605115,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -4.4211814 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.12343038,  0.        ,  0.18522035,\n",
       "       -1.45337341,  0.        ,  2.88056761,  0.47835039,  1.22293896,\n",
       "        6.02282615, -0.55582293,  2.80719361, -9.04599777,  1.31709791,\n",
       "        0.        ,  1.41886036, -2.11526084,  1.31447898,  0.        ,\n",
       "       -1.88083653, -1.16022406,  0.        ,  0.        , -3.53824703,\n",
       "       -0.63372719,  0.        , -6.38107692,  5.22173563, -1.72092071,\n",
       "        1.34919695,  3.33451544,  2.68218189,  0.        , -9.42245829,\n",
       "        4.31844858,  0.        , -0.27071409, -1.75983284,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.71381013,\n",
       "       -4.36134198,  0.        ,  2.86892206,  4.43305466,  0.        ,\n",
       "        0.        ,  3.6775742 ,  0.        ,  0.        ,  0.        ,\n",
       "        1.08341558, -3.30639853,  2.06305632,  0.33057913,  0.19251094,\n",
       "        0.        ,  0.        , -0.88649413,  0.93654874, -0.92907885,\n",
       "        0.        ,  1.98561399,  0.        , -6.21216341, -1.44129124,\n",
       "        0.        , -2.44364738,  0.        ,  0.        , -4.60931771,\n",
       "        0.        , -7.1060601 , -0.25450493,  3.80237406, -1.03990865,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.50845406,\n",
       "        1.43603562,  0.        , -1.20824397,  0.34298881,  0.        ,\n",
       "       -0.10126385,  2.32899934,  0.        ,  0.        ,  2.53418494,\n",
       "        1.09601969, -1.3079937 , -1.43857833,  1.69509419,  0.        ,\n",
       "       -0.32535721,  1.34677404,  0.        ,  1.6209045 ,  0.        ,\n",
       "        0.37218781,  0.10660404, -2.18739269, -0.21103329,  3.88906184,\n",
       "        0.14417489, -0.44632924,  0.        , -3.08581264,  0.        ,\n",
       "       -0.64647768,  0.        ,  0.        ,  0.        ,  3.45132807,\n",
       "       -5.00554243, -0.69960904, -1.49639685,  0.        ,  0.        ,\n",
       "        0.        ,  0.82544241, -1.59146572,  2.98871443,  3.62286903,\n",
       "        1.42762964,  0.        ,  0.        ,  2.47423043,  0.        ,\n",
       "        0.        , -3.93509534, -3.67117534, -1.66381531,  1.56373128,\n",
       "       -2.54003703,  1.59270721,  0.        , -3.34179223,  0.        ,\n",
       "        1.65598468, -0.63192153,  3.2586072 ,  3.79248979,  1.8805576 ,\n",
       "        0.        ,  0.        ,  0.67639555,  2.12813618,  0.        ,\n",
       "       -2.03734815, -0.92737418, -0.76446219,  0.26149847, -1.01734604,\n",
       "        0.        ,  0.        ,  0.        ,  2.90633058, -1.7841167 ,\n",
       "        0.        ,  2.43839142,  1.72382498,  0.91379309, -4.73625657,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.76208384,\n",
       "       -5.52170122, -5.29286887,  3.40864884,  1.99232504,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.62730881,  0.        ,\n",
       "        0.        , -2.27439354,  0.4710198 ,  0.        ,  2.47498796,\n",
       "        0.        , -0.08208131, -4.96373925, -0.44566027,  0.        ,\n",
       "       -6.48977714,  0.        ,  0.        ,  2.27450145, -3.93815903,\n",
       "        3.3400167 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.463294  ,  0.        , -0.97093426,\n",
       "        0.        ,  2.09674151,  2.34015509,  0.        ,  2.04765046,\n",
       "        0.        ,  2.79378918, -3.53025833,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.34513262,  1.83249431,  0.        ,  2.75072664, -0.09395582,\n",
       "        0.        , -4.52339131,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.13120524, -1.74165902,  0.        ,  2.79691941,\n",
       "        2.63991594,  0.        ,  3.2993635 , -2.01361589,  2.02896249,\n",
       "        1.14511249, -0.30690699,  2.8638261 ,  0.        , -1.90000553,\n",
       "        2.10753598,  1.25927173, -2.0796748 ,  0.        ,  0.8230681 ,\n",
       "        2.19885118,  2.00914115,  8.62446715,  0.        , -1.25440593,\n",
       "        2.36717472,  1.67806024,  0.45576057,  0.        ,  2.94290434,\n",
       "       -6.67368945,  4.84287936,  0.        , -1.54032161,  0.        ,\n",
       "       -1.45007199,  0.        ,  0.        ,  0.14619982,  1.24542242,\n",
       "       -1.1466085 ,  0.        ,  0.        , -0.87419234,  4.46233691,\n",
       "       -1.71233723, -5.01433667,  2.26989479,  3.50090393,  0.        ,\n",
       "        1.14726699,  0.        , -6.01328696,  1.50616649,  0.        ,\n",
       "        1.71264187,  0.        ,  1.61466992,  0.43339527,  0.        ,\n",
       "        0.        ,  0.04176741, -2.46692818, -1.69221917,  0.        ,\n",
       "        4.96165716,  5.70358511,  0.        ,  1.64405708,  3.47260936,\n",
       "       -4.14704621,  1.13520012,  4.72538745,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.72411832,  2.05994544,\n",
       "       -2.04054909, -5.93196356,  0.        , -6.38319172,  2.66130388,\n",
       "        0.54021669,  2.11793369, -5.40525212,  1.69551788,  0.        ,\n",
       "        0.        ,  1.63502311, -0.87789452, -1.26780838,  0.        ,\n",
       "       -1.69376272,  1.42150321,  0.75101169,  1.70050797,  0.        ,\n",
       "        6.76881923,  0.        , -1.72645458, -0.34222196,  0.        ,\n",
       "        0.        ,  0.        ,  4.20692684, -1.49838649, -0.42849111,\n",
       "        3.27441965,  0.        ,  0.        ,  1.33915726, -2.84127863,\n",
       "        0.        , -1.43255817,  0.        , -3.91065627,  0.        ,\n",
       "        3.28198124,  0.        ,  1.08150973, -0.74044771, -5.10018979,\n",
       "        0.98746237,  0.        ,  2.98754322, -3.93588581, -2.10669405,\n",
       "        0.        ,  0.        , -1.75450388,  0.80332304,  0.        ,\n",
       "        2.25687791,  0.        , -3.02195407, -0.34214784, -1.19599784,\n",
       "        0.        ,  0.        ,  1.20211888,  4.74596595, -3.36959436])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
