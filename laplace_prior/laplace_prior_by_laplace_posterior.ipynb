{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VB Lasso by Laplace posterior\n",
    "+ We consider the following approximated posterior distribution q(w):\n",
    "$$\n",
    "p(y|x,w) = N(y|x^T w,1), p(w) = Laplace(w, 0, \\beta)  \\\\\n",
    "q(w) \\propto \\prod_{j=1}^M \\exp(-\\frac{1}{\\sigma_j} |w_j - \\mu_j|),\n",
    "$$\n",
    "where $\\sigma_j \\in \\mathbb{R}_+, \\mu_j, w_j \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu = -1\n",
    "# sigma = 0.1\n",
    "\n",
    "# val = np.random.laplace(loc = mu, scale = sigma/np.sqrt(2), size = 10000)\n",
    "\n",
    "# (1/sigma**2 - 2*np.sqrt(2)/sigma**3*np.abs(val - mu) + 2/sigma**4*(val - mu)**2).mean()\n",
    "\n",
    "# 1/sigma**2\n",
    "\n",
    "# (3-np.sqrt(2))/sigma**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "data_seed = 20210112\n",
    "M = 200\n",
    "zero_ratio = 0.5\n",
    "n_zero_ind = int(M*zero_ratio) # # of zero elements in the parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(data_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = np.random.normal(scale = 3, size = M)\n",
    "zero_ind = np.random.choice(M, size = n_zero_ind)\n",
    "true_w[zero_ind] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 500\n",
    "ln_seed = 20210105\n",
    "np.random.seed(ln_seed)\n",
    "is_trace = False\n",
    "pri_beta = 1.5\n",
    "rho = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacePosteriorVB(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def __init__(self, pri_beta: float = 0.1, seed: int = -1, is_pri_optimize: bool = False, iteration: int = 1000, is_trace: bool = True):\n",
    "        \"\"\"\n",
    "        LaplacePosteriorVB is a class to calculate an approximated posterior distribution in the diagonal Laplace distribution q(w|lambda):\n",
    "        \n",
    "        q(w|lambda=(mu,sigma)) = prod_j=1^M sqrt{2}/sigma_j exp(-sqrt{2}/sigma_j |w_j-mu_j|),\n",
    "        where mu in mathbb{R}^M, sigma in mathbb{R}^M.\n",
    "        \n",
    "        The method searches an optimized posterior in terms of minimizing KL(q(w)||p(w|X^n,Y^n)),\n",
    "        where p(w|X^n,Y^n) propto p(Y|w,X) p(w), and p(Y|w,X)=N(Y|Xw, I_n), p(w)=q(w|0_M, pri_beta),\n",
    "        i.e. we consider here ordinal linear regression problem.        \n",
    "        \n",
    "        \"\"\"\n",
    "        self.pri_beta = pri_beta\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.is_trace = is_trace\n",
    "        pass\n",
    "    \n",
    "    def _initialize(self) -> (np.ndarray, np.ndarray, float):\n",
    "        \"\"\"\n",
    "        Initialize parameters for an approximated posterior distribution.\n",
    "        \"\"\"\n",
    "        if self.seed > 0:\n",
    "            np.random.seed(self.seed)\n",
    "        \n",
    "        est_mu = np.random.normal(size = M)\n",
    "        est_ln_sigma = np.random.normal(size = M)\n",
    "        est_pri_beta = pri_beta\n",
    "        return est_mu, est_ln_sigma, est_pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _calc_energy(self, post_mu: np.ndarray, post_ln_sigma: np.ndarray, X:np.ndarray, y:np.ndarray, pri_beta: float) -> float:\n",
    "        \"\"\"\n",
    "        Objective function over parameters for the posterior.\n",
    "        \"\"\"\n",
    "        \n",
    "        post_sigma = np.exp(post_ln_sigma)\n",
    "        n, M = X.shape\n",
    "        energy = 0\n",
    "        energy += ((y-X@post_mu)**2).sum()/2 + (X**2).sum(axis=0)@post_sigma**2/2 + n/2*np.log(2*np.pi) - M - M*np.log(pri_beta)\n",
    "        energy += (-np.log(post_sigma) + np.sqrt(2)/pri_beta*np.abs(post_mu) + post_sigma/pri_beta*np.exp(-np.sqrt(2)/post_sigma*np.abs(post_mu))).sum()    \n",
    "        return energy    \n",
    "    \n",
    "    def _calc_energy_wrapper(self, est_params: np.ndarray, X:np.ndarray, y:np.ndarray, pri_beta: float) -> np.ndarray:\n",
    "        post_mu = est_params[:M]\n",
    "        post_ln_sigma = est_params[M:]\n",
    "        return self._calc_energy(post_mu, post_ln_sigma, X, y, pri_beta)\n",
    "        pass    \n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \n",
    "        (est_mu, est_ln_sigma, est_pri_beta) = self._initialize()\n",
    "        res = minimize(\n",
    "            fun=self._calc_energy_wrapper, x0=np.hstack([est_mu, est_ln_sigma]), \n",
    "            args=(train_X, train_Y, est_pri_beta), method = \"L-BFGS-B\", options={\"disp\":self.is_trace, \"maxiter\": self.iteration}\n",
    "        )\n",
    "        \n",
    "        est_mu = res.x[:M]\n",
    "        est_ln_sigma = res.x[M:]\n",
    "        est_sigma = np.exp(est_ln_sigma)\n",
    "        \n",
    "        self.mu_ = est_mu\n",
    "        self.sigma_ = est_sigma\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        check_is_fitted(self, \"mu_\")\n",
    "        return X@self.mu_\n",
    "        pass\n",
    "\n",
    "    def get_params(self, deep=True) -> dict:\n",
    "        return {'pri_beta': self.pri_beta}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self,parameter, value)\n",
    "        return self\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### initialization\n",
    "# est_mu = np.random.normal(size = M)\n",
    "# est_ln_sigma = np.random.normal(size = M)\n",
    "# est_sigma = np.exp(est_ln_sigma)\n",
    "# est_pri_beta = pri_beta\n",
    "\n",
    "# def calc_energy(post_mu: np.ndarray, post_ln_sigma: np.ndarray, X:np.ndarray, y:np.ndarray, pri_beta: float) -> float:\n",
    "#     post_sigma = np.exp(post_ln_sigma)\n",
    "#     n, M = X.shape\n",
    "#     energy = 0\n",
    "#     energy += ((y-X@post_mu)**2).sum()/2 + (X**2).sum(axis=0)@post_sigma**2/2 + n/2*np.log(2*np.pi) - M - M*np.log(pri_beta)\n",
    "#     energy += (-np.log(post_sigma) + np.sqrt(2)/pri_beta*np.abs(post_mu) + post_sigma/pri_beta*np.exp(-np.sqrt(2)/post_sigma*np.abs(post_mu))).sum() \n",
    "# #     energy += (-np.log(post_sigma) + np.sqrt(2)/pri_beta*np.abs(post_mu) + post_sigma/pri_beta*np.exp(-post_sigma/np.sqrt(2)*np.abs(post_mu))).sum()    \n",
    "#     return energy\n",
    "\n",
    "# def calc_energy_dash(post_mu: np.ndarray, post_ln_sigma: np.ndarray, X:np.ndarray, y:np.ndarray, pri_beta: float) -> float:\n",
    "#     post_sigma = np.exp(post_ln_sigma)\n",
    "#     n, M = X.shape\n",
    "#     energy = 0\n",
    "#     energy += ((y-X@post_mu)**2).sum()/2 + (X**2).sum(axis=0)@post_sigma**2/2 + n/2*np.log(2*np.pi) - n*M - n*M*np.log(pri_beta)\n",
    "#     energy += n*(-np.log(post_sigma) + np.sqrt(2)/pri_beta*np.abs(post_mu) + post_sigma/pri_beta*np.exp(-post_sigma/np.sqrt(2)*np.abs(post_mu))).sum()\n",
    "#     return energy\n",
    "\n",
    "# def calc_energy_wrapper(est_params: np.ndarray, X:np.ndarray, y:np.ndarray, pri_beta: float) -> np.ndarray:\n",
    "#     post_mu = est_params[:M]\n",
    "#     post_ln_sigma = est_params[M:]\n",
    "#     return calc_energy(post_mu, post_ln_sigma, X, y, pri_beta)\n",
    "#     pass\n",
    "\n",
    "# def df_param(X :np.ndarray, y :np.ndarray, mu: np.ndarray, sigma: np.ndarray, pri_beta: float):\n",
    "#     pdf_mu = np.exp(-sigma/np.sqrt(2)*np.abs(mu))*sigma/pri_beta\n",
    "#     dFdm = -X.T @ (y - X @ mu) + np.sqrt(2)/pri_beta*np.sign(mu) - pdf_mu*sigma/np.sqrt(2)*np.sign(mu) \n",
    "#     dFds = (X**2).sum(axis = 0)*sigma - 1/sigma + pdf_mu*(1-sigma/np.sqrt(2)*np.abs(mu))\n",
    "    \n",
    "#     return dFdm, dFds\n",
    "\n",
    "# def df_param_dash(X :np.ndarray, y :np.ndarray, mu: np.ndarray, sigma: np.ndarray, pri_beta: float):\n",
    "#     n = len(y)\n",
    "#     pdf_mu = np.exp(-sigma/np.sqrt(2)*np.abs(mu))*sigma/pri_beta\n",
    "#     dFdm = -X.T @ (y - X @ mu) + n*np.sqrt(2)/pri_beta*np.sign(mu) - n*pdf_mu*sigma/np.sqrt(2)*np.sign(mu) \n",
    "#     dFds = (X**2).sum(axis = 0)*sigma - n/sigma + n*pdf_mu*(1-sigma/np.sqrt(2)*np.abs(mu))\n",
    "    \n",
    "#     return dFdm, dFds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.random.normal(size = (n, M))\n",
    "train_Y = train_X @ true_w + np.random.normal(size = n)\n",
    "\n",
    "test_X = np.random.normal(size = (n, M))\n",
    "test_Y = test_X @ true_w + np.random.normal(size = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = minimize(\n",
    "#     fun=calc_energy_wrapper, x0=np.hstack([est_mu, est_ln_sigma]), \n",
    "#     args=(train_X, train_Y, est_pri_beta), method = \"L-BFGS-B\", options={\"disp\":True, \"maxiter\": 1000}\n",
    "# )\n",
    "# est_mu = res.x[:M]\n",
    "# est_ln_sigma = res.x[M:]\n",
    "# est_sigma = np.exp(est_ln_sigma)\n",
    "\n",
    "# for ite in range(iteration):\n",
    "#     res = minimize(\n",
    "#         fun=calc_energy_wrapper, x0=np.hstack([est_mu, est_ln_sigma]), \n",
    "#         args=(train_X, train_Y, est_pri_beta), method = \"L-BFGS-B\", options={\"disp\":True, \"maxiter\": 1}\n",
    "#     )\n",
    "\n",
    "#     est_mu = res.x[:M]\n",
    "#     est_ln_sigma = res.x[M:]\n",
    "#     est_sigma = np.exp(est_ln_sigma)\n",
    "#     est_pri_beta = (np.sqrt(2)*np.abs(est_mu) + est_sigma*np.exp(-np.sqrt(2)/est_sigma*np.abs(est_mu))).mean()\n",
    "\n",
    "#     dFdm, dFds = df_param(train_X, train_Y, est_mu, est_sigma, est_pri_beta)\n",
    "    \n",
    "# #     print(res.fun, (dFdm**2).mean(), (dFds**2).mean())\n",
    "\n",
    "# post_mu = res.x[:M]\n",
    "# post_sigma = np.exp(res.x[M:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [100, 10, 5, 1, 0.5, 0.1, 0.01, 0.05, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_vb_obj = GridSearchCV(\n",
    "    LaplacePosteriorVB(**{\n",
    "        \"pri_beta\": pri_beta,\n",
    "        \"iteration\": iteration,\n",
    "        \"is_trace\": is_trace\n",
    "    })\n",
    "    , param_grid = {\n",
    "        \"is_trace\": [False],\n",
    "        \"pri_beta\": alphas\n",
    "    }\n",
    "    , cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LaplacePosteriorVB(pri_beta=1.5),\n",
       "             param_grid={'is_trace': [False],\n",
       "                         'pri_beta': [100, 10, 5, 1, 0.5, 0.1, 0.01, 0.05,\n",
       "                                      0.001]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplace_vb_obj.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=[100, 10, 5, 1, 0.5, 0.1, 0.01, 0.05, 0.001], cv=3,\n",
       "        fit_intercept=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_obj = LassoCV(alphas=alphas, fit_intercept=False, cv=3)\n",
    "lasso_obj.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_obja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.258974991483496\n",
      "5.515805691912774\n",
      "0.8991666953869315\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(((test_Y - test_X@lasso_obj.coef_)**2).mean()))\n",
    "print(np.sqrt(((test_Y - test_X@laplace_vb_obj.best_estimator_.mu_)**2).mean()))\n",
    "print(np.sqrt(((test_Y - test_X@true_w)**2).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.8.0"
   }
  },
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
