{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with laplace prior\n",
    " + In general, laplace prior gives sparse result for regression\n",
    "     + However, it is difficult to deal with it well due to non-differential point at the origin.\n",
    "         + $\\log p(w) \\equiv -1/\\beta \\sum_j |w_j| $, $|w_j|$ is non-differential at the origin.\n",
    " + By the way, non-differential point is eliminated by integrating $|w_j|$:\n",
    "     + $E[|w_j|]$ does not have non-diffenrential point when the distribution is normal distribution.\n",
    "     + It is achieved when we consider about the objective function of variational Bayes.\n",
    "         + $\\mathcal{F} := E[\\log \\frac{q(w)}{p(Y|X,w}p(w)]$\n",
    "         + Here, $\\mathcal{F}$ has a parameter that decides the form of $q(w) = N(w|m, \\Sigma)$, $(m, \\Sigma)$ is the parameter and optimized by it.\n",
    " + In this notebook, the approximated posterior distribution by Variational Bayes is studied.\n",
    "     + The objective function is optimized by a gradient descent method.\n",
    "         + Specifically, the Natural gradient descent is efficient method when we consider about a constrained parameter like positive definite matrix, positive real value, simplex, and so on.\n",
    "         + Thus, we used the natural gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation\n",
    "+ Learning Model:\n",
    "    + $p(y|x,w) = N(y|x \\cdot w, 1), y \\in mathbb{R}, x,w \\in \\mathbb{R}^M$\n",
    "    + $p(w) \\equiv \\exp(-\\frac{1}{\\beta} \\sum_j |w_j|)$, $\\beta$ is hyperparameter.\n",
    "+ Approximated Variational Posterior distribution:\n",
    "    + $q(w) = N(w|m, \\Sigma)$\n",
    "        + $m \\in \\mathbb{R}^M, \\Sigma \\in \\mathbb{R}^{M \\times M}$ is the parameters to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "+ We compare the following average generalization error:\n",
    "$$\n",
    "    G(n) = \\frac{1}{L} \\sum_{j=1}^L \\| y - X \\hat{w}(x^l, y^l) \\|^2,\n",
    "$$\n",
    "where $\\hat{w}$ is estimated parameter by $(x^l, y^l)$.  \n",
    "We evaluate the error among Lasso, Ridge, and VB laplace(this calculation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary\n",
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import invwishart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso, LassoLarsCV\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setting\n",
    "n = 100 # train size\n",
    "M = 150 # # of features\n",
    "n_zero_ind = M//2 # # of zero elements in the parameter\n",
    "prob_seed = 20201110 # random seed\n",
    "\n",
    "N = 10000 # test size\n",
    "\n",
    "datasets = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(prob_seed)\n",
    "true_w = np.random.normal(scale = 3, size = M)\n",
    "zero_ind = np.random.choice(M, size = n_zero_ind)\n",
    "true_w[zero_ind] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_vb_params = {\n",
    "    \"pri_beta\": 10,\n",
    "    \"pri_opt_flag\": True,\n",
    "    \"iteration\": 10000,\n",
    "    \"step\": 0.2,\n",
    "    \"is_trace\": False,\n",
    "    \"trace_step\": 100\n",
    "}\n",
    "ln_lasso_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5,\n",
    "    \"max_iter\": 10000\n",
    "}\n",
    "ln_ridge_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5\n",
    "}\n",
    "ln_ard_params = {\n",
    "    \"fit_intercept\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBLaplace(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        sq_sigma_diag = np.sqrt(np.diag(sigma))\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from laplace prior\n",
    "        F += ((mean + 2*sq_sigma_diag*norm.pdf(-mean/sq_sigma_diag)-2*mean*norm.cdf(-mean/sq_sigma_diag))/pri_beta).sum()\n",
    "\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "        \n",
    "        # transformation to natural parameter\n",
    "        theta1 = np.linalg.solve(est_sigma, est_mean)\n",
    "        theta2 = -np.linalg.inv(est_sigma)/2        \n",
    "        \n",
    "        F = []\n",
    "        \n",
    "        cov_X = train_X.T @ train_X\n",
    "        cov_YX = train_Y @ train_X\n",
    "        for ite in range(iteration):\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "\n",
    "            # update mean and sigma by natural gradient\n",
    "            dFdnu1 = theta1 - cov_YX\n",
    "            dFdnu1 += (1 - 2*est_mean/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag) - 2*norm.cdf(-est_mean/sq_sigma_diag)) / est_pri_beta\n",
    "            dFdnu2 = theta2 + cov_X/2\n",
    "            dFdnu2[np.diag_indices(M)] += 1/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)/est_pri_beta\n",
    "\n",
    "            theta1 += -step * dFdnu1\n",
    "            theta2 += -step * dFdnu2\n",
    "            est_sigma = -np.linalg.inv(theta2)/2\n",
    "            est_mean = est_sigma @ theta1\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "            est_pri_beta = ((est_mean + 2*sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)-2*est_mean*norm.cdf(-est_mean/sq_sigma_diag))).mean() if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBNormal(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from Normal prior\n",
    "        F += pri_beta/2*(mean@mean + np.trace(sigma)) - M/2*np.log(pri_beta) + M/2*log_2pi\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        XY_cov = train_Y@train_X\n",
    "        X_cov = train_X.T@train_X\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            sigma_inv = X_cov + est_pri_beta*np.eye(M)\n",
    "            est_mean = np.linalg.solve(sigma_inv, XY_cov)\n",
    "            est_sigma = np.linalg.inv(sigma_inv)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/(est_mean@est_mean + np.trace(est_sigma)) if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBApproxLaplace(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Laplace prior is approximated by normal distribution, and approximated posterior distribution is obtained by the approximated laplace prior.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, y:np.ndarray, pri_beta:float, mean:np.ndarray, inv_sigma:np.ndarray, h_xi: np.ndarray, v_xi: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        F = 0\n",
    "        F += pri_beta/2*np.sqrt(h_xi).sum() + v_xi@h_xi - M*np.log(pri_beta/2)\n",
    "        F += n/2*np.log(2*np.pi) + train_Y@train_Y/2 - mean @ (inv_sigma @ mean)/2 + np.linalg.slogdet(inv_sigma)[0]/2\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        X_cov = train_X.T@train_X\n",
    "        XY_cov = train_X.T @ train_Y\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            # update form of approximated laplace prior\n",
    "            est_h_xi = est_mean**2 + np.diag(est_sigma)\n",
    "            est_v_xi = -est_pri_beta/2/np.sqrt(est_h_xi)            \n",
    "            \n",
    "            # update posterior distribution\n",
    "            inv_sigma = X_cov -2*np.diag(est_v_xi)\n",
    "            est_mean = np.linalg.solve(inv_sigma, XY_cov)\n",
    "            est_sigma = np.linalg.inv(inv_sigma)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/((est_mean**2 + np.diag(est_sigma))/(2*np.sqrt(est_h_xi))).sum() if self.pri_opt_flag else pri_beta\n",
    "            \n",
    "            current_F = self._obj_func(train_Y, est_pri_beta, est_mean, inv_sigma, est_h_xi, est_v_xi)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F)            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment part\n",
    "+ By some datasets are used for train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func = lambda X, y, coef: 1 - ((y - X@coef)**2).sum() / ((y - y.mean())**2).sum()\n",
    "score_vb_laplace_exact = np.zeros(datasets)\n",
    "score_vb_laplace_approx = np.zeros(datasets)\n",
    "score_vb_normal = np.zeros(datasets)\n",
    "score_ard = np.zeros(datasets)\n",
    "score_lasso = np.zeros(datasets)\n",
    "score_ridge = np.zeros(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_error = lambda X, y, coef: ((y - X@coef)**2).mean()\n",
    "sq_error_vb_laplace_exact = np.zeros(datasets)\n",
    "sq_error_vb_laplace_approx = np.zeros(datasets)\n",
    "sq_error_vb_normal = np.zeros(datasets)\n",
    "sq_error_ard = np.zeros(datasets)\n",
    "sq_error_lasso = np.zeros(datasets)\n",
    "sq_error_ridge = np.zeros(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq_error: 307.21280965165374 299.57324833924264 529.0096422655707 254.9575357833291 298.7638424960508 229.96053166500693\n",
      "R^2 score: 0.6542613959418628 0.6628589907712077 0.4046502961332219 0.7130697036501119 0.6637698995534911 0.7412014385191878\n",
      "sq_error: 379.47310033044005 360.1096923010835 522.3127002045723 332.2856185431891 360.1365969055096 328.5345035083024\n",
      "R^2 score: 0.5823252615193514 0.6036379879753584 0.42510596858354877 0.6342631171878772 0.603608374878652 0.6383918577753993\n",
      "sq_error: 273.49125254187175 313.0690969381526 466.3817109700364 302.3911517676868 313.6430706874192 288.38580132560406\n",
      "R^2 score: 0.687354463665474 0.6421104703997472 0.4668489072040177 0.6543171200228822 0.6414543238904401 0.6703275417816094\n",
      "sq_error: 351.47545561100793 255.17667596480428 562.9807224124019 253.6546536469595 255.13005477659246 258.84414393934446\n",
      "R^2 score: 0.6077829337136951 0.7152442777046306 0.3717608333803061 0.7169427266824963 0.7152963030320761 0.7111516917026508\n",
      "sq_error: 354.9477304453857 276.0158387036575 806.680420136299 347.40804597114015 275.972495575278 391.9104233117277\n",
      "R^2 score: 0.5967675112271231 0.6864367791799875 0.08358407293448167 0.6053328448645501 0.6864860184229197 0.5547766563552228\n",
      "sq_error: 785.0782173251658 385.26907707324983 619.029623200602 353.52899951084714 385.143547616582 355.4690595550155\n",
      "R^2 score: 0.12104026662596767 0.5686595325299848 0.30694534563341325 0.6041951638796516 0.5688000730969354 0.6020231068520578\n",
      "sq_error: 353.29090450218496 264.1168336568814 488.95711880640073 236.60467134372317 263.0492870491957 217.57398368204045\n",
      "R^2 score: 0.6159716650746079 0.7129041632194308 0.468502059373063 0.7428099710075109 0.7140645897715452 0.7634963889199653\n",
      "sq_error: 387.42616058882317 286.3098538957116 575.6426837082091 291.25662528621393 286.61921332570205 335.11560794770367\n",
      "R^2 score: 0.5657804464773264 0.6791095966808485 0.35483110193570355 0.673565353459642 0.6787628727699895 0.6244090759375294\n",
      "sq_error: 458.4815240596529 335.71779983980986 602.0441590322101 270.0499753186965 303.40624381206607 247.86926342472898\n",
      "R^2 score: 0.4835466869667677 0.6218330273458553 0.32183155872593816 0.6958040899817433 0.6582301541308727 0.7207893980954562\n",
      "sq_error: 501.83767993430786 264.13593464699954 818.5697901783394 206.7208424237976 237.2129579688331 198.05327144550375\n",
      "R^2 score: 0.4382733692101889 0.7043422712714613 0.08374267479597763 0.7686092396570305 0.7344782167872281 0.7783111923749011\n",
      "sq_error: 415.5232778371075 301.6250350356695 504.7704054778102 305.4162859207405 301.7012734158888 336.97095138157596\n",
      "R^2 score: 0.5269495427356787 0.6566164439963699 0.4253465837878241 0.6523003128421252 0.6565296507827344 0.6163770572238864\n",
      "sq_error: 253.5822093731569 273.55440657434 280.11975199310234 258.64940057376094 273.1828906109106 229.55341178585206\n",
      "R^2 score: 0.7072460979353645 0.6841887285800612 0.6766092122784404 0.7013961607487165 0.684617633857928 0.7349867043169944\n",
      "sq_error: 238.73259522402063 256.27062646583227 462.11989681782825 218.3861234793452 231.6365796825756 206.93572389296838\n",
      "R^2 score: 0.7332224653395 0.7136241665269776 0.4835929016105278 0.7559591241773539 0.7411520801886282 0.7687546511964639\n",
      "sq_error: 449.85280659059185 210.0733885413109 437.2020328215135 186.01804668469237 210.09250000774463 189.11219685757138\n",
      "R^2 score: 0.5003225923141028 0.7666593946458446 0.5143745349707745 0.7933790475719015 0.7666381664399409 0.7899421968626824\n",
      "sq_error: 269.9008789508254 232.30759765239736 329.3508890419322 234.7267948038075 232.30109861980313 224.00683756415154\n",
      "R^2 score: 0.7011152448531133 0.7427455600996815 0.6352810698084378 0.7400665723503195 0.7427527570446235 0.7519377148497978\n",
      "sq_error: 354.1328579174598 252.59454035197226 508.2607727567017 296.41636387196917 252.58838039056937 332.59153577395153\n",
      "R^2 score: 0.6065084784512914 0.7193318614869659 0.4352506401363877 0.6706396386999416 0.7193387060723551 0.6304439236857904\n",
      "sq_error: 279.0758053569442 273.4911364211528 407.1819643064591 227.1095072130301 273.49839686016037 240.74198671006155\n",
      "R^2 score: 0.6870551620797991 0.6933175942985788 0.543401859358844 0.7453281633138538 0.6933094527224735 0.7300412269160805\n",
      "sq_error: 476.25125599570043 282.04954399975406 552.946857597601 259.9784854854027 281.9388476862561 226.7467332900538\n",
      "R^2 score: 0.4602139884233519 0.6803233660679017 0.37328673653063404 0.7053388353118171 0.6804488299292712 0.7430039012815179\n",
      "sq_error: 314.8448490208842 320.3167001775434 541.6766808582217 311.952176702125 320.4214239246507 306.4445688332361\n",
      "R^2 score: 0.6502427516863263 0.6441641399202873 0.39825807548755954 0.6534561855844152 0.644047803605003 0.6595745190397786\n",
      "sq_error: 338.38651339283354 362.7926515340125 737.7731086648066 337.3955708424972 362.77190227676056 345.9036068189695\n",
      "R^2 score: 0.6182647810194002 0.5907321160961443 0.16771511851830678 0.6193826673903936 0.5907555234186801 0.6097847169756173\n",
      "sq_error: 409.9731947369334 329.0582727226804 598.0738091746919 349.138046417745 329.1088826016556 361.3393349777175\n",
      "R^2 score: 0.5428547274323472 0.633079831302202 0.3331109984247259 0.6106896513178321 0.6330233981811695 0.5970844657690444\n",
      "sq_error: 330.77893420528255 289.66171626660827 377.10088430712744 276.5497417578591 289.8936802087361 267.3653542503935\n",
      "R^2 score: 0.6216455616977916 0.6686766156405495 0.5686611857309422 0.683674468397436 0.6684112886261766 0.6941798344204742\n",
      "sq_error: 201.03847256508968 291.46258579132746 424.9219126523438 273.18131403230086 291.46959399456284 233.34459590421432\n",
      "R^2 score: 0.7749665372025581 0.67374983444881 0.5243614408594859 0.6942130713396637 0.6737419897799666 0.7388045095478231\n",
      "sq_error: 525.712167627758 336.92765738702224 799.4717078253617 381.5051096742186 336.7550636607254 418.61184525104784\n",
      "R^2 score: 0.4107573590965219 0.6223558158678073 0.10391493776459348 0.5723913346784442 0.6225492669411301 0.5308003801352734\n",
      "sq_error: 521.4681007024519 380.3232003478793 720.4382826179692 402.3846569477764 359.6676725958499 430.522765468782\n",
      "R^2 score: 0.41386636293399903 0.5725141760729071 0.19022254610852696 0.5477169511257769 0.5957311275805947 0.5160895287285909\n",
      "sq_error: 400.3378324166663 305.8782137999679 428.7807512694958 263.9990611303209 282.2936871264773 297.0376859227376\n",
      "R^2 score: 0.5484128719037604 0.6549647499380711 0.5163288293792574 0.702205067364545 0.6815684526251203 0.6649369990528589\n",
      "sq_error: 369.70096635660036 287.7352531480365 657.0844859953842 260.9756573875391 287.749315894739 280.9271329613213\n",
      "R^2 score: 0.5861946287652599 0.6779386474976157 0.2645269707041058 0.7078905964116019 0.6779229071002422 0.6855589594730975\n",
      "sq_error: 259.1509088563779 290.3597169252718 612.8444431856567 244.66004588252903 290.3955612591813 237.53784583515298\n",
      "R^2 score: 0.7110917213768557 0.6762993177659498 0.31678482654810136 0.727246518193944 0.676259357555685 0.7351865349385407\n",
      "sq_error: 420.0614110687161 373.9754987346165 564.5687009219275 329.63053930228546 374.0047460912894 305.7969977461282\n",
      "R^2 score: 0.5226432591717758 0.575015175111234 0.35842553506627783 0.6254086765112342 0.5749819384879896 0.652493053747162\n",
      "sq_error: 399.9660217329112 318.761448833959 377.8581560457845 298.876400871507 318.7850185624806 312.9855841685032\n",
      "R^2 score: 0.5533380817434046 0.644023260812127 0.5780270332037998 0.6662298813371683 0.6439969393258451 0.6504734557058967\n",
      "sq_error: 452.4130906464659 330.9140303841049 632.8368504041413 337.78937299553945 331.0501482177409 365.5045466232726\n",
      "R^2 score: 0.4926386384155189 0.6288944849425537 0.29030133583649453 0.6211840909225383 0.6287418347853473 0.5901027439875415\n",
      "sq_error: 363.5675339695798 331.81961725453203 384.0541319604323 304.73596948560845 331.8369294183092 302.9057261832627\n",
      "R^2 score: 0.6002152747211712 0.6351257960857177 0.5776878810888342 0.6649074120749872 0.6351067593511555 0.6669199771349986\n",
      "sq_error: 521.5491621963596 401.35487376061633 994.3786310121404 425.5202590182059 384.6284342142497 484.72758885700136\n",
      "R^2 score: 0.3990131422914095 0.5375143478485593 -0.14583347484999098 0.5096683076207957 0.556788408804368 0.4414430477751341\n",
      "sq_error: 559.8375682840816 310.3583934469086 814.3937121715428 287.46472300626885 278.43854758265786 301.63488953083095\n",
      "R^2 score: 0.3629412632030349 0.6468323362263273 0.07327292964353527 0.6728838440168141 0.6831550445207353 0.6567591162426334\n",
      "sq_error: 200.95333501843047 241.85784169749016 259.5136600593158 202.25699074120905 241.85795796634918 178.66210467244588\n",
      "R^2 score: 0.7711994843393268 0.7246266209421806 0.7045241412036563 0.7697151740561041 0.7246264885613227 0.7965797299441303\n",
      "sq_error: 502.6534304899614 401.2516419813329 690.8901056212277 400.394009048641 382.1227124804873 408.9490357015768\n",
      "R^2 score: 0.4327963446456218 0.5472200441825025 0.22038651367692397 0.5481878134343725 0.5688054906904867 0.5385341592566433\n",
      "sq_error: 375.0270492463306 282.15733526332724 687.2152524866594 263.91518895978385 282.1298266738266 293.7548861064467\n",
      "R^2 score: 0.5678835584305051 0.6748905874343066 0.2081717569610141 0.6959096882248196 0.6749222835848416 0.6615275715896591\n",
      "sq_error: 249.40458466292407 247.37255623965444 551.8330529589366 172.0074726085959 219.47878977849763 166.670642976128\n",
      "R^2 score: 0.7163597209336536 0.7186706853043603 0.3724169852336522 0.8043811119264808 0.7503934209306801 0.8104505266019513\n",
      "sq_error: 351.3727697742386 352.00920644664336 389.4929254351692 338.86280697151005 351.7472588795109 330.2048894322402\n",
      "R^2 score: 0.5992659528962982 0.598540108820157 0.5557906310492386 0.6135333306053767 0.598838855102555 0.6234075230114386\n",
      "sq_error: 691.9806672577238 429.7335425525935 973.7041440748321 426.2195248749099 412.6521866331254 430.31626743849216\n",
      "R^2 score: 0.20633693414534404 0.5071196970943024 -0.11678411375905262 0.5111500785420822 0.5267110555663889 0.5064513442899893\n",
      "sq_error: 425.4086241521377 312.23088237071556 692.0852538315786 307.82411285560755 312.23513109423135 316.9465049990292\n",
      "R^2 score: 0.5357236039353197 0.6592419133578054 0.24468186779513323 0.6640513106116568 0.6592372764465397 0.6540954443988415\n",
      "sq_error: 516.8704448554723 370.61838539525826 829.1050687925268 376.4783571093533 370.60732203802553 439.49831121665153\n",
      "R^2 score: 0.4181893008591917 0.5828166534429198 0.06672512515152229 0.5762204274952816 0.5828291068143023 0.5052825669077192\n",
      "sq_error: 309.0771515327994 306.6550863565014 385.6947410995177 263.1790307324862 278.8551617949957 257.4588321840126\n",
      "R^2 score: 0.6597780385963453 0.6624441682692797 0.5754399163147865 0.7103011801678999 0.6930454107560942 0.7165977865657802\n",
      "sq_error: 315.89756099148207 290.81090283810755 520.2798554687743 259.7801277077736 290.87386792846524 262.9009147601769\n",
      "R^2 score: 0.6430011376905427 0.6713518105852361 0.41202674720907506 0.7064199870641565 0.671280653132952 0.7028931556960343\n",
      "sq_error: 324.31408879608847 322.44499065713154 467.53416059717836 273.0169530048025 283.3509764372721 295.64147779219627\n",
      "R^2 score: 0.6301031888798025 0.6322349909357581 0.46675336943690504 0.6886101967598293 0.6768237143165231 0.6628057687035795\n",
      "sq_error: 313.11890463807174 331.63791387202014 545.9580614762787 302.06074441069217 331.7001400661852 285.44733566617566\n",
      "R^2 score: 0.64821560819572 0.627409779152237 0.3866243086501774 0.6606392853114773 0.627339868956639 0.6793042007937954\n",
      "sq_error: 363.56119179113125 229.67249150595595 671.2563733669986 242.3542211814364 229.66304105911172 278.9661196926744\n",
      "R^2 score: 0.5834793696088096 0.7368714452874403 0.23096267120404224 0.7223423861960165 0.736882272367354 0.6803972848154487\n",
      "sq_error: 526.1055603205122 363.5194099675828 654.1040150198784 318.1456211125703 329.51498861565034 385.51073759681367\n",
      "R^2 score: 0.3946458229628439 0.5817227380682013 0.24736663595072084 0.633931295975573 0.6208493317703914 0.5564188009061661\n",
      "sq_error: 511.4127095396237 381.2288000057347 534.3221505196703 353.2933233633549 360.30521210143723 342.2608585211508\n",
      "R^2 score: 0.42493098555149933 0.5713190810294155 0.39916997218555994 0.6027317282343396 0.5948470592169006 0.6151374204774114\n",
      "sq_error: 324.46506068594186 251.7229948034723 427.6314343225973 246.5814722974357 251.65319546686342 250.84789294560943\n",
      "R^2 score: 0.6428254976795273 0.7229007178724416 0.5292588841218757 0.7285605591458928 0.7229775537057448 0.7238640390691865\n",
      "sq_error: 366.03171963766795 304.7301233113202 666.5771959743442 299.80052123276204 304.7165750803292 317.8911938734855\n",
      "R^2 score: 0.5824077770088576 0.6523445297803538 0.23952641771682337 0.6579685327833849 0.6523599864623669 0.6373295449630865\n",
      "sq_error: 428.314588301213 376.47221889893916 517.8172846384497 364.79941554329486 376.53732561709893 377.6951185937629\n",
      "R^2 score: 0.5233915144967473 0.5810792838153622 0.42379709087709516 0.5940682346493191 0.5810068360977598 0.5797184981045975\n",
      "sq_error: 305.14133312195986 279.32239420108937 362.64131400967494 267.5392255206717 279.7587833853267 264.84539391452205\n",
      "R^2 score: 0.6557350391929453 0.6848643475850031 0.590862711133725 0.6981582925987571 0.6843720068592449 0.7011975132209638\n",
      "sq_error: 374.8366637397175 313.4660852815036 500.0061454393666 278.1833880621922 288.2567574955129 315.2158777862655\n",
      "R^2 score: 0.577206553173163 0.6464289129637797 0.43602282776771284 0.6862256954393027 0.6748635342745369 0.6444552511641597\n",
      "sq_error: 377.541002556461 340.1640164469181 654.8905000401979 331.63483661767077 312.3813905980695 353.4471007952001\n",
      "R^2 score: 0.5698976925411667 0.6124783072630524 0.2539355638384344 0.6221949205592255 0.6441288337063842 0.5973459502748549\n",
      "sq_error: 377.02916318037177 309.2183043746936 662.5636183720438 277.2838766433929 309.232521072654 306.2743596761986\n",
      "R^2 score: 0.5721861804861477 0.6491309511915719 0.24819112172747926 0.685366847074196 0.6491148195485872 0.6524714360900788\n",
      "sq_error: 331.25098709143356 354.04987418619373 345.75321171519926 298.53106343450156 354.08711470331303 286.0570978916298\n",
      "R^2 score: 0.6243186147797665 0.5984617333846477 0.6078712197598464 0.6614272324828241 0.5984194978303312 0.6755743198484597\n",
      "sq_error: 414.1470709911268 360.79719178671775 512.2905562221141 362.3985479260222 337.74671102284407 404.5802337266866\n",
      "R^2 score: 0.5407932856090585 0.5999476886185516 0.431971684422935 0.5981721032219438 0.6255060862944748 0.5514010049798675\n",
      "sq_error: 341.01841017130647 285.20190073008973 750.3713960185509 309.2888589687813 285.21089759182286 297.2657882273852\n",
      "R^2 score: 0.6131534026654097 0.6764708837995868 0.14878900191586508 0.6491469694393694 0.676460677883295 0.6627857756360371\n",
      "sq_error: 311.0020477816773 320.6443211528249 451.42776684364685 294.68795507785376 320.63908199034887 306.46929549473276\n",
      "R^2 score: 0.6502315838837628 0.6393874022816095 0.49230181561172726 0.6685792263063475 0.6393932945050662 0.6553293432051572\n",
      "sq_error: 299.33033075087627 296.0209791037348 528.3518541790369 262.34349079099803 267.78620635767163 277.6348159386696\n",
      "R^2 score: 0.6631071256894507 0.6668317632352454 0.4053460123630894 0.7047353923421817 0.6986096780294632 0.6875251802394072\n",
      "sq_error: 262.60623610036953 275.0127828623751 491.2135355898185 262.84137263190485 275.0096013611169 266.06761379821353\n",
      "R^2 score: 0.7024656008309793 0.6884089108931788 0.4434521954019911 0.7021991897675104 0.688412515552685 0.6985438396842583\n",
      "sq_error: 471.55982219603817 324.01579922727075 579.2021482291865 314.51892280683916 323.9809555947525 376.0522574944205\n",
      "R^2 score: 0.46254159408705275 0.6307042993351065 0.3398566870287777 0.6415283259417572 0.6307440122247718 0.5713959558477957\n",
      "sq_error: 369.6869662283972 220.68186322155753 597.091359730902 243.33638932812852 219.57023626687402 263.440937956116\n",
      "R^2 score: 0.5869271170044097 0.753419238996246 0.33283487948714374 0.7281060111396851 0.754661324849776 0.7056420223553006\n",
      "sq_error: 368.1549418110809 289.6824677738498 509.0914230099884 253.8575360073498 270.8619511346746 274.78862176650364\n",
      "R^2 score: 0.5836519201022938 0.6723967940119027 0.424266219489275 0.7129113705107905 0.6936810009462331 0.6892403114639454\n",
      "sq_error: 368.075007314612 259.993663751367 554.4416551407608 254.100191525615 260.0006881898231 286.5463391214531\n",
      "R^2 score: 0.587873957809062 0.708890423127844 0.37920304172229635 0.7154892231954761 0.7088825580080668 0.6791599366987537\n",
      "sq_error: 363.6398101242009 378.6066988523528 562.7124464904339 333.7423144200363 378.59697687461346 325.4256702888209\n",
      "R^2 score: 0.5956555614482754 0.5790133290766775 0.3742993976250034 0.6288996831809155 0.579024139300204 0.6381472647389472\n",
      "sq_error: 424.76025487681034 350.2358456787254 533.1008098865863 317.7142965436996 350.23779405459095 327.12101051211204\n",
      "R^2 score: 0.5225244479582882 0.606297783655052 0.40073817978025206 0.6428554522415388 0.6062955934740468 0.6322813086078112\n",
      "sq_error: 620.4931723132996 326.9823997570376 418.70778334268266 322.46834261950727 326.9715167456048 297.6346048444675\n",
      "R^2 score: 0.29080115629629777 0.6262722135126668 0.5214337738974568 0.6314316000219717 0.6262846523588438 0.6598155676476565\n",
      "sq_error: 482.0956075520912 352.25179835915844 534.1768791959593 309.5637439164294 352.0588247381353 315.7508537010854\n",
      "R^2 score: 0.46777704091324745 0.6111217535909944 0.41028046124506334 0.6582484278383027 0.6113347922289694 0.6514179945669762\n",
      "sq_error: 338.1112205656668 278.74183074618674 674.9865570258582 280.0012545459179 278.7265759727064 255.48373749249308\n",
      "R^2 score: 0.6208768278304002 0.6874475596756137 0.24313944907433427 0.6860353712683163 0.6874646648107313 0.7135267950177728\n",
      "sq_error: 492.79946364413536 315.97575734108096 1076.8387283456852 375.2303968763732 315.95988914200433 437.31059298331195\n",
      "R^2 score: 0.4575870904309183 0.6522128319189182 -0.1852513463781733 0.5869926281505664 0.6522302976766265 0.5186623999721929\n",
      "sq_error: 340.1255110949248 305.82148181787244 581.6319328438649 285.0773979938133 305.8764946951923 290.86890981690294\n",
      "R^2 score: 0.6246080410240498 0.6624689374608568 0.35806064658204706 0.6853639042006541 0.6624082204869388 0.6789718903769829\n",
      "sq_error: 336.2241883617114 283.57900784517227 422.7899742037598 284.2316063169771 283.06747741069296 312.30145409775673\n",
      "R^2 score: 0.6173262085055244 0.6772443569597995 0.5188012997436425 0.6765016015597615 0.6778265556760216 0.6445538849802872\n",
      "sq_error: 564.1382441395655 351.4695269959733 866.5391725615752 355.4513816389763 319.6388265335666 409.9396666066324\n",
      "R^2 score: 0.36406380207446953 0.6037988968016006 0.02317626490145841 0.5993102709573705 0.6396806949949552 0.5378872542876452\n",
      "sq_error: 404.7200774787736 328.47111983805473 643.7692152528422 313.1514314590543 328.4060467548641 339.8166547805143\n",
      "R^2 score: 0.543456318620432 0.6294688041870129 0.27379741247014666 0.6467501483044258 0.6295422097495529 0.616670495978242\n",
      "sq_error: 287.47234056561774 306.44444701732823 423.77780540941524 294.6704020529695 306.46392535743735 290.3776195960663\n",
      "R^2 score: 0.6713489562017083 0.64965920832496 0.5155185441064613 0.6631198152120468 0.6496369398284649 0.668027513227391\n",
      "sq_error: 280.8365576065727 204.86667245957128 543.9331865329999 193.83178740832162 204.8683191116411 225.67545289992006\n",
      "R^2 score: 0.6749457363432281 0.7628770772163871 0.370424552509086 0.7756494045281898 0.7628751712990072 0.7387919550325838\n",
      "sq_error: 441.4088394368214 345.4217064289615 615.2533740219327 365.54525142230517 345.3558723377382 391.7242970858695\n",
      "R^2 score: 0.49984649931676495 0.6086080290035754 0.30286595706408503 0.5858063526995421 0.6086826245899067 0.5561432826307968\n",
      "sq_error: 539.7173205999717 298.56809493370724 640.1529893472934 284.9041749722421 298.5940577770715 310.72473615827255\n",
      "R^2 score: 0.3922446312282405 0.6637937014172481 0.27914780337488965 0.6791801276038612 0.6637644656361439 0.6501045651074321\n",
      "sq_error: 450.952993635572 368.51892711390525 760.0080865132834 374.2440045224529 353.5561874758332 394.702289241984\n",
      "R^2 score: 0.4827691749325723 0.5773188083587149 0.12829138470503754 0.5707523002006806 0.5944806639789115 0.547287203762051\n",
      "sq_error: 502.0718903377708 384.4236179169834 505.57494758106674 300.66848835506244 351.73775339688063 301.4275775473043\n",
      "R^2 score: 0.43415729726939656 0.5667487004514771 0.43020929815510023 0.6611420130246743 0.603586169899724 0.6602865078900158\n",
      "sq_error: 250.87440973131362 264.05612369782745 321.747928304884 240.14732784646927 263.9908969913105 233.84532188794682\n",
      "R^2 score: 0.7104584390252855 0.6952450338705938 0.6286612193664936 0.722838880844632 0.695320313937789 0.7301122119287261\n",
      "sq_error: 295.2299428421029 247.79198602659415 517.5328054351139 239.0229503934754 223.6808031268864 281.69080819074253\n",
      "R^2 score: 0.6511405361700189 0.7071957588230244 0.3884556041963506 0.7175577195368533 0.7356868199184002 0.66713910057621\n",
      "sq_error: 400.44546267611105 329.4177031877628 527.9298538134494 292.0306812274989 304.8818775250429 287.490379160988\n",
      "R^2 score: 0.5554995967176793 0.634341463287526 0.41399003160973 0.6758416122161799 0.6615765937071829 0.6808814148552222\n",
      "sq_error: 417.22819311188374 317.8896448953259 741.4014959996733 312.1691808312646 317.7266057459066 351.47553346140194\n",
      "R^2 score: 0.5346876640299834 0.6454746450768787 0.17315448071179984 0.6518543733417113 0.6456564739386941 0.6080180960652957\n",
      "sq_error: 371.07375453783624 357.08934614977 383.3714690324858 346.4377751309706 357.08477194524704 360.76332388382434\n",
      "R^2 score: 0.5788638786926887 0.5947349540121025 0.5649070528059543 0.6068235516286962 0.5947401453324999 0.5905653119563983\n",
      "sq_error: 443.3319186337393 383.7924827687955 817.881252797819 396.5219576059086 383.767785773653 415.5157344622774\n",
      "R^2 score: 0.49974148226570914 0.5669261551499094 0.077097664277756 0.5525621358995582 0.5669540233941373 0.5311294389585719\n",
      "sq_error: 427.7504845045884 298.04066672442076 788.6785365809856 249.68709865135918 266.7679312796211 263.0495413337633\n",
      "R^2 score: 0.5211864064744658 0.6663804535105438 0.11717223494401363 0.7205062734161802 0.7013864006225388 0.7055486768012962\n",
      "sq_error: 270.2041898953212 217.16437517071674 359.80811476250756 179.18073498085548 217.14697947676314 198.9262075307607\n",
      "R^2 score: 0.6979914560877959 0.7572743162853248 0.5978407112439015 0.7997288166047654 0.7572937595374939 0.7776592054119651\n",
      "sq_error: 587.0945998279207 327.4446424618267 679.5420935657085 293.9517743620269 305.49417025350306 308.7460514660491\n",
      "R^2 score: 0.326778122431963 0.6245189496507751 0.22076850263839842 0.6629252500219499 0.6496895748241697 0.6459606398685762\n",
      "sq_error: 416.9077398130505 301.92023331111375 711.6204117245985 285.92042724837074 302.2843739223714 334.79938845064015\n",
      "R^2 score: 0.5331410437240842 0.6619056171386645 0.20311778612850828 0.6798224175377618 0.6614978475304878 0.6250870921130642\n",
      "sq_error: 248.64042837454733 239.0010375499844 391.36868478016584 234.2154585709265 239.02980471343636 227.58138227684339\n",
      "R^2 score: 0.720988736692253 0.7318055561011506 0.5608265643947724 0.7371756821314781 0.7317732750973373 0.7446200950123304\n",
      "sq_error: 888.7458489384779 301.2928569928513 526.3361757289256 244.49278727305577 301.30652634240374 220.81078648066656\n",
      "R^2 score: 0.0028930238559294885 0.6619717437456678 0.4094898184411857 0.7256972124279955 0.6619564077485272 0.7522666622064049\n",
      "sq_error: 349.6485363730325 265.123335133877 451.0528873734618 283.1087123909424 265.13033198679096 305.600310096613\n",
      "R^2 score: 0.6056175143177653 0.7009568493920144 0.49123951513782216 0.6806704273118525 0.7009489573634282 0.6553012600270688\n",
      "sq_error: 286.95465644141996 265.5352819660561 516.6749518279302 253.61783521175343 265.544833370649 240.8334288584655\n",
      "R^2 score: 0.6750435597614103 0.6992995302620055 0.4149011025345597 0.7127952202153822 0.6992887139522992 0.7272726823714151\n",
      "sq_error: 467.11770186506203 335.50152912794135 715.5314419744387 322.5675526342006 335.2790452885122 323.3972841327794\n",
      "R^2 score: 0.46714464103899667 0.6172832093032568 0.18377153801096135 0.6320373893736071 0.6175370033805282 0.6310908894363296\n",
      "sq_error: 213.36002228022758 206.86734943782358 478.8988276040561 193.70495370319392 206.0316615168286 188.72318720604414\n",
      "R^2 score: 0.7569977979465842 0.7643925000142676 0.45456759694306925 0.7793835518225234 0.7653442903396572 0.7850574368174047\n",
      "sq_error: 283.9401236298932 271.78699757614146 677.4028989600337 292.13506397884174 248.33216258457495 309.5093874712677\n",
      "R^2 score: 0.6821030851331982 0.6957096203036586 0.2415855535024104 0.6729281005584786 0.7219694513807482 0.6534759577421314\n",
      "sq_error: 560.7502919014906 309.44273896319163 727.5911501284353 343.5313827938455 309.15361398181733 393.0771787983767\n",
      "R^2 score: 0.36569513540251075 0.6499671289101977 0.1769694770919088 0.6114070194968022 0.650294178908764 0.5553622168816127\n"
     ]
    }
   ],
   "source": [
    "for dataset_ind in range(datasets):\n",
    "    vb_laplace_exact_obj = VBLaplace(**ln_vb_params)\n",
    "    vb_laplace_approx_obj = VBApproxLaplace(**ln_vb_params)\n",
    "    vb_normal_obj = VBNormal(**ln_vb_params)\n",
    "    lasso_obj = LassoCV(**ln_lasso_params)\n",
    "    ridge_obj = RidgeCV(**ln_ridge_params)\n",
    "    ard_obj = ARDRegression(**ln_ard_params)\n",
    "    \n",
    "    # data generation\n",
    "    train_X = np.random.normal(size = (n, M))\n",
    "    train_Y = train_X @ true_w + np.random.normal(size = n)\n",
    "\n",
    "    lasso_obj.fit(train_X, train_Y)\n",
    "    ridge_obj.fit(train_X, train_Y)\n",
    "    ard_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_exact_obj.fit(train_X, train_Y)\n",
    "    vb_normal_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_approx_obj.fit(train_X, train_Y)\n",
    "\n",
    "    test_X = np.random.normal(size = (N, M))\n",
    "    test_Y = test_X @ true_w + np.random.normal(size = N)\n",
    "    \n",
    "    ### evaluation by square error\n",
    "    sq_error_lasso[dataset_ind] = sq_error(test_X, test_Y, lasso_obj.coef_)\n",
    "    sq_error_ridge[dataset_ind] = sq_error(test_X, test_Y, ridge_obj.coef_)\n",
    "    sq_error_ard[dataset_ind] = sq_error(test_X, test_Y, ard_obj.coef_)\n",
    "    sq_error_vb_laplace_exact[dataset_ind] = sq_error(test_X, test_Y, vb_laplace_exact_obj.mean_)\n",
    "    sq_error_vb_normal[dataset_ind] = sq_error(test_X, test_Y, vb_normal_obj.mean_)\n",
    "    sq_error_vb_laplace_approx[dataset_ind] = sq_error(test_X, test_Y, vb_laplace_approx_obj.mean_)\n",
    "\n",
    "    print(\n",
    "        \"sq_error:\"\n",
    "        , sq_error_lasso[dataset_ind]\n",
    "        , sq_error_ridge[dataset_ind]\n",
    "        , sq_error_ard[dataset_ind]\n",
    "        , sq_error_vb_laplace_exact[dataset_ind]\n",
    "        , sq_error_vb_normal[dataset_ind]\n",
    "        , sq_error_vb_laplace_approx[dataset_ind]\n",
    "    )    \n",
    "    \n",
    "    ### evaluation by R^2 score\n",
    "    score_lasso[dataset_ind] = score_func(test_X, test_Y, lasso_obj.coef_)\n",
    "    score_ridge[dataset_ind] = score_func(test_X, test_Y, ridge_obj.coef_)\n",
    "    score_ard[dataset_ind] = score_func(test_X, test_Y, ard_obj.coef_)\n",
    "    score_vb_laplace_exact[dataset_ind] = score_func(test_X, test_Y, vb_laplace_exact_obj.mean_)\n",
    "    score_vb_normal[dataset_ind] = score_func(test_X, test_Y, vb_normal_obj.mean_)\n",
    "    score_vb_laplace_approx[dataset_ind] = score_func(test_X, test_Y, vb_laplace_approx_obj.mean_)\n",
    "    \n",
    "    print(\n",
    "        \"R^2 score:\"\n",
    "        , score_lasso[dataset_ind]\n",
    "        , score_ridge[dataset_ind]\n",
    "        , score_ard[dataset_ind]\n",
    "        , score_vb_laplace_exact[dataset_ind]\n",
    "        , score_vb_normal[dataset_ind]\n",
    "        , score_vb_laplace_approx[dataset_ind]\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393.94768472453995 308.2709538942517 572.4249348002895 293.35773252079895 301.32563165797364 304.6139525695377\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sq_error_lasso.mean()\n",
    "    , sq_error_ridge.mean()\n",
    "    , sq_error_ard.mean()\n",
    "    , sq_error_vb_laplace_exact.mean()\n",
    "    , sq_error_vb_normal.mean()\n",
    "    , sq_error_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5560140895408846 0.6525618684686846 0.3547590596218103 0.6693602376627976 0.660415787359578 0.6566254504698098\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    score_lasso.mean()\n",
    "    , score_ridge.mean()\n",
    "    , score_ard.mean()\n",
    "    , score_vb_laplace_exact.mean()\n",
    "    , score_vb_normal.mean()\n",
    "    , score_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , -0.76668197,\n",
       "        0.07758316,  0.        , -0.0995576 ,  0.        , -0.90644613,\n",
       "        0.        ,  0.        , -1.16645995,  1.00565264, -1.27819984,\n",
       "        0.30094245, -0.627204  ,  3.38047157,  1.22344481,  0.0473449 ,\n",
       "       -0.03814966,  0.        ,  0.        ,  3.52029545,  0.        ,\n",
       "        4.81596502,  0.        , -3.25347577,  0.66002526,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.63380714,  1.33677451,\n",
       "        0.        , -2.69622796,  3.58475763,  0.        ,  0.        ,\n",
       "        2.71306942,  0.        ,  1.88162727, -2.59235379,  3.48865255,\n",
       "        0.        ,  0.        ,  0.        ,  2.00792993, -0.4410573 ,\n",
       "        0.        , -4.15620415,  3.9016001 ,  0.        ,  6.5176337 ,\n",
       "       -3.96303101, -0.03691128,  1.35713552,  2.36783035,  0.        ,\n",
       "        0.        ,  0.18762913, -1.26910508, -3.83069906,  0.26426108,\n",
       "       -1.0842188 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        2.82239462,  0.16265215,  0.        ,  0.        ,  0.        ,\n",
       "        1.42660064, -0.55960312, -1.35619478, -5.20937925,  0.        ,\n",
       "       -0.97513867,  0.        ,  5.61036017, -2.75649377, -4.37142083,\n",
       "        0.6528961 ,  3.65665585,  4.40974135, -0.18317878, -3.07988735,\n",
       "        0.        , -2.53854171,  3.27560309,  0.        ,  7.81317023,\n",
       "        0.        ,  0.        ,  0.        , -4.21542812,  0.        ,\n",
       "       -5.32304818,  0.        ,  0.        ,  1.46339651, -2.80157424,\n",
       "        2.40381311,  1.93661268,  0.        , -3.68530166,  3.68187137,\n",
       "        4.6779508 ,  1.30380009,  0.        ,  0.17820812,  0.        ,\n",
       "       -4.04242208,  0.        ,  0.        ,  0.        , -1.69246901,\n",
       "        1.35555417,  2.7963506 ,  0.        ,  3.07879094, -3.43986175,\n",
       "       -5.22595885,  0.39853712,  3.12602451, -4.18756991,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  4.31956641,\n",
       "       -1.51861904, -4.10136198,  0.30293722,  0.        ,  0.        ,\n",
       "        0.        , -0.21288762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.77619219,  3.10719351,\n",
       "       -2.62922584,  1.34767249,  1.17694762,  0.        ,  0.82839278,\n",
       "        0.        , -2.43049864, -4.70204062,  0.31933329,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.37294018,\n",
       "        0.        ,  0.49227329,  1.88058534, -2.15501367,  0.        ,\n",
       "        2.51412901, -2.62329196,  1.88505711,  0.        , -1.44365597,\n",
       "        0.        , -5.9506191 ,  4.61010472, -0.3914984 , -2.56273853,\n",
       "        0.        ,  0.        , -0.03003618,  2.00666083, -1.11247555,\n",
       "        5.80470762, -0.75163024, -0.23380517,  0.67443324,  1.1577714 ,\n",
       "       -1.46410966,  0.        , -3.65760862, -1.67716493, -2.42723579,\n",
       "        0.        , -1.72682638, -0.84503449, -0.45390357,  0.        ,\n",
       "        0.        ,  0.        , -3.61775795, -1.11710953,  3.11547965,\n",
       "       -3.40428624,  1.72675508,  0.        , -1.09670842,  2.21402638,\n",
       "        0.        ,  5.68384374, 10.00605115,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -4.4211814 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.12343038,  0.        ,  0.18522035,\n",
       "       -1.45337341,  0.        ,  2.88056761,  0.47835039,  1.22293896,\n",
       "        6.02282615, -0.55582293,  2.80719361, -9.04599777,  1.31709791,\n",
       "        0.        ,  1.41886036, -2.11526084,  1.31447898,  0.        ,\n",
       "       -1.88083653, -1.16022406,  0.        ,  0.        , -3.53824703,\n",
       "       -0.63372719,  0.        , -6.38107692,  5.22173563, -1.72092071,\n",
       "        1.34919695,  3.33451544,  2.68218189,  0.        , -9.42245829,\n",
       "        4.31844858,  0.        , -0.27071409, -1.75983284,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.71381013,\n",
       "       -4.36134198,  0.        ,  2.86892206,  4.43305466,  0.        ,\n",
       "        0.        ,  3.6775742 ,  0.        ,  0.        ,  0.        ,\n",
       "        1.08341558, -3.30639853,  2.06305632,  0.33057913,  0.19251094,\n",
       "        0.        ,  0.        , -0.88649413,  0.93654874, -0.92907885,\n",
       "        0.        ,  1.98561399,  0.        , -6.21216341, -1.44129124,\n",
       "        0.        , -2.44364738,  0.        ,  0.        , -4.60931771,\n",
       "        0.        , -7.1060601 , -0.25450493,  3.80237406, -1.03990865,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.50845406,\n",
       "        1.43603562,  0.        , -1.20824397,  0.34298881,  0.        ,\n",
       "       -0.10126385,  2.32899934,  0.        ,  0.        ,  2.53418494,\n",
       "        1.09601969, -1.3079937 , -1.43857833,  1.69509419,  0.        ,\n",
       "       -0.32535721,  1.34677404,  0.        ,  1.6209045 ,  0.        ,\n",
       "        0.37218781,  0.10660404, -2.18739269, -0.21103329,  3.88906184,\n",
       "        0.14417489, -0.44632924,  0.        , -3.08581264,  0.        ,\n",
       "       -0.64647768,  0.        ,  0.        ,  0.        ,  3.45132807,\n",
       "       -5.00554243, -0.69960904, -1.49639685,  0.        ,  0.        ,\n",
       "        0.        ,  0.82544241, -1.59146572,  2.98871443,  3.62286903,\n",
       "        1.42762964,  0.        ,  0.        ,  2.47423043,  0.        ,\n",
       "        0.        , -3.93509534, -3.67117534, -1.66381531,  1.56373128,\n",
       "       -2.54003703,  1.59270721,  0.        , -3.34179223,  0.        ,\n",
       "        1.65598468, -0.63192153,  3.2586072 ,  3.79248979,  1.8805576 ,\n",
       "        0.        ,  0.        ,  0.67639555,  2.12813618,  0.        ,\n",
       "       -2.03734815, -0.92737418, -0.76446219,  0.26149847, -1.01734604,\n",
       "        0.        ,  0.        ,  0.        ,  2.90633058, -1.7841167 ,\n",
       "        0.        ,  2.43839142,  1.72382498,  0.91379309, -4.73625657,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.76208384,\n",
       "       -5.52170122, -5.29286887,  3.40864884,  1.99232504,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.62730881,  0.        ,\n",
       "        0.        , -2.27439354,  0.4710198 ,  0.        ,  2.47498796,\n",
       "        0.        , -0.08208131, -4.96373925, -0.44566027,  0.        ,\n",
       "       -6.48977714,  0.        ,  0.        ,  2.27450145, -3.93815903,\n",
       "        3.3400167 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.463294  ,  0.        , -0.97093426,\n",
       "        0.        ,  2.09674151,  2.34015509,  0.        ,  2.04765046,\n",
       "        0.        ,  2.79378918, -3.53025833,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.34513262,  1.83249431,  0.        ,  2.75072664, -0.09395582,\n",
       "        0.        , -4.52339131,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.13120524, -1.74165902,  0.        ,  2.79691941,\n",
       "        2.63991594,  0.        ,  3.2993635 , -2.01361589,  2.02896249,\n",
       "        1.14511249, -0.30690699,  2.8638261 ,  0.        , -1.90000553,\n",
       "        2.10753598,  1.25927173, -2.0796748 ,  0.        ,  0.8230681 ,\n",
       "        2.19885118,  2.00914115,  8.62446715,  0.        , -1.25440593,\n",
       "        2.36717472,  1.67806024,  0.45576057,  0.        ,  2.94290434,\n",
       "       -6.67368945,  4.84287936,  0.        , -1.54032161,  0.        ,\n",
       "       -1.45007199,  0.        ,  0.        ,  0.14619982,  1.24542242,\n",
       "       -1.1466085 ,  0.        ,  0.        , -0.87419234,  4.46233691,\n",
       "       -1.71233723, -5.01433667,  2.26989479,  3.50090393,  0.        ,\n",
       "        1.14726699,  0.        , -6.01328696,  1.50616649,  0.        ,\n",
       "        1.71264187,  0.        ,  1.61466992,  0.43339527,  0.        ,\n",
       "        0.        ,  0.04176741, -2.46692818, -1.69221917,  0.        ,\n",
       "        4.96165716,  5.70358511,  0.        ,  1.64405708,  3.47260936,\n",
       "       -4.14704621,  1.13520012,  4.72538745,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.72411832,  2.05994544,\n",
       "       -2.04054909, -5.93196356,  0.        , -6.38319172,  2.66130388,\n",
       "        0.54021669,  2.11793369, -5.40525212,  1.69551788,  0.        ,\n",
       "        0.        ,  1.63502311, -0.87789452, -1.26780838,  0.        ,\n",
       "       -1.69376272,  1.42150321,  0.75101169,  1.70050797,  0.        ,\n",
       "        6.76881923,  0.        , -1.72645458, -0.34222196,  0.        ,\n",
       "        0.        ,  0.        ,  4.20692684, -1.49838649, -0.42849111,\n",
       "        3.27441965,  0.        ,  0.        ,  1.33915726, -2.84127863,\n",
       "        0.        , -1.43255817,  0.        , -3.91065627,  0.        ,\n",
       "        3.28198124,  0.        ,  1.08150973, -0.74044771, -5.10018979,\n",
       "        0.98746237,  0.        ,  2.98754322, -3.93588581, -2.10669405,\n",
       "        0.        ,  0.        , -1.75450388,  0.80332304,  0.        ,\n",
       "        2.25687791,  0.        , -3.02195407, -0.34214784, -1.19599784,\n",
       "        0.        ,  0.        ,  1.20211888,  4.74596595, -3.36959436])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "+ We experimented the performance of the rigorously derived variational linear regression algorithm for the Laplace prior by comparing:\n",
    "    1. Ordinal optimized Lasso by cross-validation\n",
    "    2. Ordinal optimized Ridge by cross-validation\n",
    "    3. Variational Bayes linear regression for the normal prior\n",
    "    4. Bayesian ARD\n",
    "    5. Variational Bayes linear regression for the approximated Laplace prior.\n",
    "+ Results are as follows:\n",
    "    1. n > M with non-zero elements: ridge, vb for the normal prior gives the best performance, although vb for the Laplace prior gives better performance.\n",
    "    2. n > M with zero-elements: lasso, vb for the approximated Laplace gives the best performance. although vb for the Laplace prior also gives better performance.\n",
    "    3. M > n with zero-elements: results is similar with 1.\n",
    "    4. M > n with zero-elements: results is similar with 2.\n",
    "    5. M >> n, especially # of non-zero elements is larger than # of samples, vb for the Laplace prior gives the best performance.\n",
    "+ Summary of results:\n",
    "    + Derived algorithm can estimate every case, and # of features are extremely larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.5.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
