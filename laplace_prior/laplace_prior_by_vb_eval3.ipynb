{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with laplace prior\n",
    " + In general, laplace prior gives sparse result for regression\n",
    "     + However, it is difficult to deal with it well due to non-differential point at the origin.\n",
    "         + $\\log p(w) \\equiv -1/\\beta \\sum_j |w_j| $, $|w_j|$ is non-differential at the origin.\n",
    " + By the way, non-differential point is eliminated by integrating $|w_j|$:\n",
    "     + $E[|w_j|]$ does not have non-diffenrential point when the distribution is normal distribution.\n",
    "     + It is achieved when we consider about the objective function of variational Bayes.\n",
    "         + $\\mathcal{F} := E[\\log \\frac{q(w)}{p(Y|X,w}p(w)]$\n",
    "         + Here, $\\mathcal{F}$ has a parameter that decides the form of $q(w) = N(w|m, \\Sigma)$, $(m, \\Sigma)$ is the parameter and optimized by it.\n",
    " + In this notebook, the approximated posterior distribution by Variational Bayes is studied.\n",
    "     + The objective function is optimized by a gradient descent method.\n",
    "         + Specifically, the Natural gradient descent is efficient method when we consider about a constrained parameter like positive definite matrix, positive real value, simplex, and so on.\n",
    "         + Thus, we used the natural gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulation\n",
    "+ Learning Model:\n",
    "    + $p(y|x,w) = N(y|x \\cdot w, 1), y \\in mathbb{R}, x,w \\in \\mathbb{R}^M$\n",
    "    + $p(w) \\equiv \\exp(-\\frac{1}{\\beta} \\sum_j |w_j|)$, $\\beta$ is hyperparameter.\n",
    "+ Approximated Variational Posterior distribution:\n",
    "    + $q(w) = N(w|m, \\Sigma)$\n",
    "        + $m \\in \\mathbb{R}^M, \\Sigma \\in \\mathbb{R}^{M \\times M}$ is the parameters to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook\n",
    "+ We compare the following average generalization error:\n",
    "$$\n",
    "    G(n) = \\frac{1}{L} \\sum_{j=1}^L \\| y - X \\hat{w}(x^l, y^l) \\|^2,\n",
    "$$\n",
    "where $\\hat{w}$ is estimated parameter by $(x^l, y^l)$.  \n",
    "We evaluate the error among Lasso, Ridge, and VB laplace(this calculation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary\n",
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import invwishart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, Lasso, LassoLarsCV\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data setting\n",
    "n = 100 # train size\n",
    "M = 200 # # of features\n",
    "zero_ratio = 1\n",
    "n_zero_ind = int(M*zero_ratio) # # of zero elements in the parameter\n",
    "prob_seed = 20201110 # random seed\n",
    "\n",
    "N = 10000 # test size\n",
    "\n",
    "datasets = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(prob_seed)\n",
    "true_w = np.random.normal(scale = 3, size = M)\n",
    "zero_ind = np.random.choice(M, size = n_zero_ind)\n",
    "true_w[zero_ind] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_vb_params = {\n",
    "    \"pri_beta\": 10,\n",
    "    \"pri_opt_flag\": True,\n",
    "    \"iteration\": 10000,\n",
    "    \"step\": 0.2,\n",
    "    \"is_trace\": False,\n",
    "    \"trace_step\": 100\n",
    "}\n",
    "ln_lasso_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5,\n",
    "    \"max_iter\": 10000\n",
    "}\n",
    "ln_ridge_params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"cv\": 5\n",
    "}\n",
    "ln_ard_params = {\n",
    "    \"fit_intercept\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBLaplace(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        sq_sigma_diag = np.sqrt(np.diag(sigma))\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from laplace prior\n",
    "        F += ((mean + 2*sq_sigma_diag*norm.pdf(-mean/sq_sigma_diag)-2*mean*norm.cdf(-mean/sq_sigma_diag))/pri_beta).sum()\n",
    "\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "        \n",
    "        # transformation to natural parameter\n",
    "        theta1 = np.linalg.solve(est_sigma, est_mean)\n",
    "        theta2 = -np.linalg.inv(est_sigma)/2        \n",
    "        \n",
    "        F = []\n",
    "        \n",
    "        cov_X = train_X.T @ train_X\n",
    "        cov_YX = train_Y @ train_X\n",
    "        for ite in range(iteration):\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "\n",
    "            # update mean and sigma by natural gradient\n",
    "            dFdnu1 = theta1 - cov_YX\n",
    "            dFdnu1 += (1 - 2*est_mean/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag) - 2*norm.cdf(-est_mean/sq_sigma_diag)) / est_pri_beta\n",
    "            dFdnu2 = theta2 + cov_X/2\n",
    "            dFdnu2[np.diag_indices(M)] += 1/sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)/est_pri_beta\n",
    "\n",
    "            theta1 += -step * dFdnu1\n",
    "            theta2 += -step * dFdnu2\n",
    "            est_sigma = -np.linalg.inv(theta2)/2\n",
    "            est_mean = est_sigma @ theta1\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            sq_sigma_diag = np.sqrt(np.diag(est_sigma))\n",
    "            est_pri_beta = ((est_mean + 2*sq_sigma_diag*norm.pdf(-est_mean/sq_sigma_diag)-2*est_mean*norm.cdf(-est_mean/sq_sigma_diag))).mean() if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBNormal(BaseEstimator, RegressorMixin):\n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, X:np.ndarray, y:np.ndarray, pri_beta:float, mean:np.ndarray, sigma:np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        n, M = X.shape\n",
    "\n",
    "        log_2pi = np.log(2*np.pi)\n",
    "\n",
    "        F = 0\n",
    "        # const values\n",
    "        F += -M/2*log_2pi -M/2 + M*log_2pi + n*M/2*log_2pi + M*np.log(2*pri_beta)\n",
    "\n",
    "        F += ((y - X@mean)**2).sum()/2 - np.linalg.slogdet(sigma)[1]/2 + np.trace(X.T @ X @ sigma)/2\n",
    "\n",
    "        # term obtained from Normal prior\n",
    "        F += pri_beta/2*(mean@mean + np.trace(sigma)) - M/2*np.log(pri_beta) + M/2*log_2pi\n",
    "        \n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        pri_beta = self.pri_beta\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        XY_cov = train_Y@train_X\n",
    "        X_cov = train_X.T@train_X\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            sigma_inv = X_cov + est_pri_beta*np.eye(M)\n",
    "            est_mean = np.linalg.solve(sigma_inv, XY_cov)\n",
    "            est_sigma = np.linalg.inv(sigma_inv)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/(est_mean@est_mean + np.trace(est_sigma)) if self.pri_opt_flag else pri_beta\n",
    "            current_F = self._obj_func(train_X, train_Y, est_pri_beta, est_mean, est_sigma)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBApproxLaplace(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Laplace prior is approximated by normal distribution, and approximated posterior distribution is obtained by the approximated laplace prior.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, pri_beta: float = 20, pri_opt_flag: bool = True,\n",
    "        seed: int = -1, iteration: int = 1000, tol: float = 1e-8, step: float = 0.1,\n",
    "        is_trace: bool = False, trace_step: int = 20\n",
    "    ):\n",
    "        self.pri_beta = pri_beta\n",
    "        self.pri_opt_flag = pri_opt_flag\n",
    "        self.seed = seed\n",
    "        self.iteration = iteration\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.is_trace = is_trace\n",
    "        self.trace_step = trace_step\n",
    "        pass\n",
    "    \n",
    "    def _initialization(self, M: int):\n",
    "        seed = self.seed\n",
    "        \n",
    "        if seed > 0:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        mean = np.random.normal(size = M)\n",
    "        sigma = invwishart.rvs(df = M+2, scale = np.eye(M), size = 1)\n",
    "        pri_beta = np.random.gamma(shape = 3, size = 1) if self.pri_opt_flag else self.pri_beta\n",
    "        \n",
    "        self.mean_ = mean\n",
    "        self.sigma_ = sigma\n",
    "        self.pri_beta_ = pri_beta\n",
    "        pass\n",
    "    \n",
    "    def _obj_func(self, y:np.ndarray, pri_beta:float, mean:np.ndarray, inv_sigma:np.ndarray, h_xi: np.ndarray, v_xi: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate objective function.\n",
    "\n",
    "        + Input:\n",
    "            1. X: input matrix (n, M) matrix\n",
    "            2. y: output vector (n, ) matrix\n",
    "            3. mean: mean parameter of vb posterior\n",
    "            4. sigma: covariance matrix of vb posterior\n",
    "\n",
    "        + Output:\n",
    "            value of the objective function.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        F = 0\n",
    "        F += pri_beta/2*np.sqrt(h_xi).sum() + v_xi@h_xi - M*np.log(pri_beta/2)\n",
    "        F += n/2*np.log(2*np.pi) + train_Y@train_Y/2 - mean @ (inv_sigma @ mean)/2 + np.linalg.slogdet(inv_sigma)[0]/2\n",
    "        return F\n",
    "    \n",
    "    def fit(self, train_X:np.ndarray, train_Y:np.ndarray):\n",
    "        iteration = self.iteration\n",
    "        step = self.step\n",
    "        tol = self.tol\n",
    "        \n",
    "        is_trace = self.is_trace\n",
    "        trace_step = self.trace_step\n",
    "        \n",
    "        M = train_X.shape[1]\n",
    "        \n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            self._initialization(M)\n",
    "        \n",
    "        est_mean = self.mean_\n",
    "        est_sigma = self.sigma_\n",
    "        est_pri_beta = self.pri_beta_\n",
    "                \n",
    "        F = []\n",
    "        X_cov = train_X.T@train_X\n",
    "        XY_cov = train_X.T @ train_Y\n",
    "        \n",
    "        for ite in range(iteration):\n",
    "            # update form of approximated laplace prior\n",
    "            est_h_xi = est_mean**2 + np.diag(est_sigma)\n",
    "            est_v_xi = -est_pri_beta/2/np.sqrt(est_h_xi)            \n",
    "            \n",
    "            # update posterior distribution\n",
    "            inv_sigma = X_cov -2*np.diag(est_v_xi)\n",
    "            est_mean = np.linalg.solve(inv_sigma, XY_cov)\n",
    "            est_sigma = np.linalg.inv(inv_sigma)\n",
    "            \n",
    "            # update pri_beta by extreme value\n",
    "            est_pri_beta = M/((est_mean**2 + np.diag(est_sigma))/(2*np.sqrt(est_h_xi))).sum() if self.pri_opt_flag else pri_beta\n",
    "            \n",
    "            current_F = self._obj_func(train_Y, est_pri_beta, est_mean, inv_sigma, est_h_xi, est_v_xi)\n",
    "            if is_trace and ite % trace_step == 0:\n",
    "                print(current_F)            \n",
    "            \n",
    "            if ite > 0 and np.abs(current_F - F[ite-1]) < tol:\n",
    "                if is_trace:\n",
    "                    print(current_F, (dFdnu1**2).sum(), (dFdnu2**2).sum())                            \n",
    "                break\n",
    "            else:\n",
    "                F.append(current_F)\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        self.F_ = F\n",
    "        self.mean_ = est_mean\n",
    "        self.sigma_ = est_sigma\n",
    "        self.pri_beta_ = est_pri_beta\n",
    "        \n",
    "        return self\n",
    "        pass\n",
    "    \n",
    "    def predict(self, test_X: np.ndarray):\n",
    "        if not hasattr(self, \"mean_\"):\n",
    "            raise ValueError(\"fit has not finished yet, should fit before predict.\")\n",
    "        return test_X @ self.mean_\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment part\n",
    "+ By some datasets are used for train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_func = lambda X, y, coef: 1 - ((y - X@coef)**2).sum() / ((y - y.mean())**2).sum()\n",
    "score_vb_laplace_exact = np.zeros(datasets)\n",
    "score_vb_laplace_approx = np.zeros(datasets)\n",
    "score_vb_normal = np.zeros(datasets)\n",
    "score_ard = np.zeros(datasets)\n",
    "score_lasso = np.zeros(datasets)\n",
    "score_ridge = np.zeros(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_error = lambda X, y, coef: ((y - X@coef)**2).mean()\n",
    "sq_error_vb_laplace_exact = np.zeros(datasets)\n",
    "sq_error_vb_laplace_approx = np.zeros(datasets)\n",
    "sq_error_vb_normal = np.zeros(datasets)\n",
    "sq_error_ard = np.zeros(datasets)\n",
    "sq_error_lasso = np.zeros(datasets)\n",
    "sq_error_ridge = np.zeros(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq_error: 211.99947382656495 262.8633089588862 244.28250191764744 213.0808993575275 262.8720650855691 184.89152016220785\n",
      "R^2 score: 0.6112105411694024 0.517930484487177 0.5520061441282424 0.6092272964029909 0.5179144264767819 0.6609242807600602\n",
      "sq_error: 157.20510380218326 266.92466949358436 168.06530062795468 210.27424979392399 266.8903924153819 161.33171087517715\n",
      "R^2 score: 0.7063578628601705 0.5014135768513759 0.6860721893766204 0.6072304358981974 0.5014776027274757 0.698649807009929\n",
      "sq_error: 128.47485340937857 201.0191447016561 136.20878445692813 131.46938256864007 195.73172187705399 97.6653494646435\n",
      "R^2 score: 0.764963029453435 0.6322476380495341 0.7508142705672125 0.7594847195497569 0.6419206581753738 0.8213271526965937\n",
      "sq_error: 92.92312836929125 224.46967769591458 121.5171440724955 143.2676857345334 224.45365108880972 90.91516803436357\n",
      "R^2 score: 0.827647020853728 0.5836556693922094 0.7746110988105437 0.7342683906033993 0.5836853953983028 0.8313713675455113\n",
      "sq_error: 163.34886882269143 231.6154019927571 110.0552959185726 177.08552072185796 231.6171083705561 135.52256727071492\n",
      "R^2 score: 0.6975030069474832 0.571083882291775 0.7961945110191758 0.6720648393981419 0.5710807223424168 0.7490330396187361\n",
      "sq_error: 215.43099279864924 290.2311902897391 223.23094292384508 232.4298576345199 288.32200917837054 199.91014741604616\n",
      "R^2 score: 0.5995982246626483 0.46057397619246876 0.5851011746463111 0.5680039978033598 0.464122395556376 0.6284453926824292\n",
      "sq_error: 167.22102397879758 251.89340037974975 199.53723265720342 202.6802812613491 249.42254825216764 168.95938444705803\n",
      "R^2 score: 0.6905969508548738 0.5339306967351758 0.6308034316908199 0.6249879618497949 0.5385024256007851 0.6873805249737518\n",
      "sq_error: 289.9404562600794 259.6694827275609 276.0803802058594 199.13637865098502 255.60913449987612 192.745561645778\n",
      "R^2 score: 0.46241118850859564 0.5185376666618791 0.48810964366479825 0.6307742268720951 0.5260661013140073 0.6426236657624254\n",
      "sq_error: 231.37964459700274 297.8147775972549 263.93921785413045 249.8824292372509 295.12477650183445 214.43543753066248\n",
      "R^2 score: 0.5726764724226839 0.44998073815365625 0.5125438201970262 0.5385046021345892 0.4549487670365946 0.6039698835099045\n",
      "sq_error: 200.1767520408745 279.17527502557294 253.53006562463366 226.2092905690733 279.2546252029061 197.2863778894624\n",
      "R^2 score: 0.6281579403749314 0.4814127604552849 0.5290504975348348 0.5798007128502396 0.481265362053271 0.6335270087936691\n",
      "sq_error: 241.5992934987546 291.5577613254132 300.7177612220086 254.76508949410726 288.4805066494721 250.50506000517495\n",
      "R^2 score: 0.5522270610736202 0.45963552390872686 0.4426586527645031 0.5278259666797966 0.4653388161250106 0.5357213785270257\n",
      "sq_error: 300.18785979465656 329.1518985679566 335.967919888559 283.02831390443214 329.1298931660001 269.04186053811657\n",
      "R^2 score: 0.43599995204559616 0.38158163123719013 0.3687755292372371 0.46823971254617935 0.3816229755066326 0.4945177917953204\n",
      "sq_error: 129.16816056183563 251.71780157225797 118.31469277149085 177.76397579752364 247.2489266740976 126.16264049423735\n",
      "R^2 score: 0.7635374603830265 0.5391911569563375 0.7834064323200182 0.6745752127563216 0.5473721320747659 0.7690395353910069\n",
      "sq_error: 239.76281314206886 288.01285198376144 254.4232212483259 241.7993531417001 288.0017612961479 211.89120876363796\n",
      "R^2 score: 0.5601262354387624 0.4716057265767596 0.5332299506513369 0.5563899574706419 0.47162607377926447 0.6112600513196987\n",
      "sq_error: 188.3792563697978 287.4217833467261 247.26642837580317 251.64921491564718 284.9897351892526 212.9533381166565\n",
      "R^2 score: 0.6566460570379885 0.4761238338708421 0.5493139489928598 0.5413255586115846 0.480556664429971 0.6118555210466408\n",
      "sq_error: 128.71004727143747 215.139996182098 121.64809044087173 148.36502336635738 215.13968651135764 107.77071396305003\n",
      "R^2 score: 0.7628555292186545 0.6036108942535816 0.7758669766601539 0.7266418147257989 0.603611464812799 0.8014356340449673\n",
      "sq_error: 209.43629197482105 297.6476036164995 276.4263427925887 239.45509182116464 295.2831194238618 204.9424792104753\n",
      "R^2 score: 0.6040006233155423 0.43721183949376474 0.4773367193772249 0.5472414727601234 0.4416825749982748 0.612497465180139\n",
      "sq_error: 286.76234260933796 304.2475744606996 242.60674011398194 248.3426609514196 300.2105727804196 228.97953035758053\n",
      "R^2 score: 0.4616499079693408 0.42882420257614096 0.544544936831021 0.533776669691699 0.43640302274594067 0.5701278273867523\n",
      "sq_error: 345.1533557945869 274.49737891229086 245.13520941469912 223.98301319690347 270.98780013075515 205.20603038506837\n",
      "R^2 score: 0.3676522383178663 0.4970994770043551 0.550893252577505 0.5896457192953561 0.5035292979801418 0.6240466105307124\n",
      "sq_error: 315.3922059277488 294.84345701713727 331.63632809939924 234.08792057171016 289.62640911135964 220.19782939926958\n",
      "R^2 score: 0.41328014642144884 0.45150670600491016 0.38306142572089297 0.5645294084603836 0.4612119096398135 0.5903689571420463\n",
      "sq_error: 238.05067898863638 296.64100302189144 226.12783171948763 256.28835202409294 296.5949101331937 243.91018581619304\n",
      "R^2 score: 0.5668049534285083 0.4601846394010223 0.5885016711189051 0.5336167699143274 0.4602685173851172 0.5561420586876344\n",
      "sq_error: 193.32440446513846 257.02845684484384 138.45848902005474 205.97649908341566 257.0525009299176 158.65415622049957\n",
      "R^2 score: 0.6354308725325821 0.5152984409522956 0.7388964384907706 0.6115716856472952 0.5152530988696944 0.7008116618157378\n",
      "sq_error: 241.14068015226246 269.9365876391305 260.1855407554522 190.72027544474747 269.9448024730832 166.05793514638245\n",
      "R^2 score: 0.5495390612883063 0.49574709425313357 0.5139624601958269 0.6437264991790409 0.49573174859759606 0.6897967887486562\n",
      "sq_error: 349.2894204252823 282.47843094945335 164.08544146739482 217.2383834021756 280.0476983497842 186.07944762977638\n",
      "R^2 score: 0.3461321244616249 0.4712019296048411 0.692832955294125 0.5933309400908209 0.4757522476734857 0.6516602966248062\n",
      "sq_error: 315.29920170621426 269.2939349504662 395.83061224505167 224.78968635355625 269.34975573928494 221.89353395731877\n",
      "R^2 score: 0.43260819413519813 0.51539626097007 0.28768913881502056 0.5954831937736145 0.5152958095321936 0.6006949200617515\n",
      "sq_error: 257.513345053712 293.26311885675665 388.1062722900107 236.97527574486952 290.2246598755301 214.93781183746447\n",
      "R^2 score: 0.5164532474880443 0.4493239613460248 0.27123183632983416 0.5550186923782299 0.4550294403094799 0.5963996316992677\n",
      "sq_error: 254.76488093489715 284.64550290828396 234.37068542608404 243.5820766162129 284.6290105185153 224.01179332945543\n",
      "R^2 score: 0.528986229054478 0.4737424121585413 0.5666913746646416 0.5496611934081219 0.473772903577407 0.5858430756814612\n",
      "sq_error: 222.90292568424098 267.10240190441993 189.60570540073448 211.31694124111513 263.2048510134211 185.17660394546456\n",
      "R^2 score: 0.5888684281676273 0.507345047185578 0.6502832277750539 0.6102381072811056 0.5145338546863956 0.6584524495899784\n",
      "sq_error: 240.3625188146881 240.95671463711523 241.00083112468897 189.59932089930805 240.94286079950064 192.81635506531438\n",
      "R^2 score: 0.5578985771206952 0.5568056662132067 0.5567245222726915 0.6512678850267906 0.5568311477290102 0.6453507587241691\n",
      "sq_error: 325.74755605816546 306.4588562968997 303.95295973589623 260.30681912557145 303.55340487666854 234.78176940128887\n",
      "R^2 score: 0.3847937811478156 0.4212223830698034 0.42595501457987484 0.508385033264571 0.4267096131320297 0.5565915939427604\n",
      "sq_error: 266.3075915818868 250.9529644594375 231.26135080086877 192.98486285361807 250.97434967220886 158.51027211174664\n",
      "R^2 score: 0.5118943437158756 0.54003729038924 0.5761293445098739 0.6462849497585488 0.5399980941979015 0.7094721936490915\n",
      "sq_error: 236.79715075604184 309.45271853090264 226.2754054788061 248.75487183024688 306.4746803701352 229.65704818097376\n",
      "R^2 score: 0.5675856699714399 0.4349096282120588 0.5867993869450634 0.5457497233375304 0.4403478117880698 0.5806241827300419\n",
      "sq_error: 177.67737272606442 199.93613190863297 188.89462966210172 141.9502009437601 195.53722397715543 114.81403949490138\n",
      "R^2 score: 0.6700748514974018 0.6287430582807453 0.6492457774086053 0.7364158395197076 0.6369112922560392 0.7868043721642576\n",
      "sq_error: 185.63599664569824 252.55545511703315 179.3874936713721 221.64027293433062 252.55338703765236 194.11126027434864\n",
      "R^2 score: 0.6507779214246361 0.5248877233662259 0.6625327277989799 0.5830459705621347 0.5248916138777273 0.6348340892242444\n",
      "sq_error: 173.7066064383167 260.2466327391091 185.75829396220135 203.5429435647287 260.2477959252676 132.83032768035162\n",
      "R^2 score: 0.6757644216823695 0.5142313858894894 0.6532691006687863 0.6200728033759741 0.5142292147208474 0.7520628662511305\n",
      "sq_error: 149.43106075226808 279.9548086836373 200.3044972838481 222.19752526812758 279.9295373101515 162.58994303949996\n",
      "R^2 score: 0.7241841986606766 0.4832670028095053 0.6302833885265293 0.5898738309229798 0.48331364802565946 0.6998958904300359\n",
      "sq_error: 198.15067196728833 239.09387262193016 151.39155641584145 183.212841317909 239.17200907178716 148.15922877988828\n",
      "R^2 score: 0.6353594796647958 0.56001504685176 0.7214064663129576 0.6628483510705312 0.5598712587159431 0.7273546552308452\n",
      "sq_error: 273.573413456852 309.38563290644674 322.7862378835315 239.36433004380896 307.007645537452 221.7018229317108\n",
      "R^2 score: 0.48389560157160894 0.41633478218543063 0.3910541414868942 0.548432057042856 0.42082092623370426 0.5817529031464352\n",
      "sq_error: 256.1143023096087 238.6481305484274 109.3978620448049 176.10049254698868 234.52264790332717 131.91270258145414\n",
      "R^2 score: 0.5201755347486968 0.5528980201769611 0.7950455316945608 0.6700796327855845 0.5606270204172357 0.752864477285282\n",
      "sq_error: 211.4874374612459 290.4130726270489 223.18736211250817 239.67700395356937 290.4079890194112 212.28622086069413\n",
      "R^2 score: 0.6079077953282418 0.46158172192754965 0.5862164395386219 0.5556450727410355 0.46159114680379887 0.6064268716955923\n",
      "sq_error: 287.1235121532348 277.28776556177365 146.65039277253217 206.6449990531972 273.31406099233544 159.12990420133676\n",
      "R^2 score: 0.4773374760486375 0.4952418827615769 0.7330463679197274 0.6238357633720031 0.5024753776576383 0.7103294093114131\n",
      "sq_error: 387.96384125833634 276.8414619113306 111.20587146906212 224.33692992347392 276.82495499600566 174.30680383513678\n",
      "R^2 score: 0.2775408308442102 0.4844708931852384 0.7929144601563876 0.5822438723212043 0.48450163206103747 0.6754090580490967\n",
      "sq_error: 305.4699630338638 276.09866071645234 287.35896530276665 221.38277579131815 276.1149574840634 200.97250301575644\n",
      "R^2 score: 0.44320865193780346 0.496744806030443 0.47622023429207594 0.5964774639497559 0.4967151013121228 0.6336800195796275\n",
      "sq_error: 216.1801236457523 272.3741008463038 147.0331881514656 216.4375749079925 267.90982801406614 172.63528387758103\n",
      "R^2 score: 0.5947310513429456 0.48938522362825465 0.7243595545468171 0.5942484121408814 0.49775431476728993 0.6763637710151984\n",
      "sq_error: 304.94526161392986 270.26792586829964 376.66764303538974 250.20879987037415 270.31049497088725 250.8816246563062\n",
      "R^2 score: 0.42618287435036983 0.4914354020251128 0.2912224865935903 0.5291807664300392 0.4913552995176693 0.5279147084408576\n",
      "sq_error: 349.65519171479167 285.13001214706395 338.4360562864606 224.4468555461774 285.0635079992826 194.9647202943207\n",
      "R^2 score: 0.35100222882434706 0.4707679257636399 0.37182615496654436 0.5834024134391518 0.47089136463915704 0.6381244382262493\n",
      "sq_error: 211.66077023302185 275.4521321915408 311.201150889131 214.88188646669406 270.19628264985664 181.52781801761685\n",
      "R^2 score: 0.6081495594471551 0.4900517501110545 0.42386910931956256 0.6021862634908625 0.49978197530167934 0.6639351005645056\n",
      "sq_error: 147.08344888149006 249.4800201799586 139.98050419679976 171.5172280141132 246.54401466515623 128.41335634237123\n",
      "R^2 score: 0.7304637416301138 0.5428179602211372 0.7434801697073632 0.6856878715011109 0.5481983068680993 0.7646774272941499\n",
      "sq_error: 222.82697845915416 293.95637179205966 266.3550199885595 232.26602064611143 293.96292654648585 195.05036098835254\n",
      "R^2 score: 0.5844955289079936 0.4518608669821632 0.5033289843611368 0.5668945891177259 0.4518486443608728 0.6362904633936579\n",
      "sq_error: 302.97531742197816 288.7079014120198 310.38441086175635 235.84754229926156 284.7315146252996 213.7615753751609\n",
      "R^2 score: 0.443298849619009 0.46951447329849694 0.4296850315816141 0.5666425924404233 0.4768208740883797 0.607224390649413\n",
      "sq_error: 187.19823514065743 299.38261028920977 249.68422569497335 234.62803542070858 299.3913320700845 199.7637979961201\n",
      "R^2 score: 0.654589369871852 0.44759128743011223 0.5392927413789048 0.567073816163373 0.44757519435196147 0.6314039003050103\n",
      "sq_error: 214.23102140938514 245.5857146898466 129.28576345603182 177.71828053491757 245.71282727028267 148.39980153246267\n",
      "R^2 score: 0.5974633182532976 0.5385483482957784 0.7570741068389444 0.6660701775979054 0.538309505778946 0.7211591333143419\n",
      "sq_error: 165.12026367739864 281.76326086196633 133.98093580742884 221.63322702716192 281.75107944091485 165.276105930603\n",
      "R^2 score: 0.6930682554353622 0.4762478736132132 0.7509512070176901 0.5880198377235965 0.47627051689594146 0.6927785700049517\n",
      "sq_error: 238.35550160522607 324.39357653870974 267.21072018173896 269.5089526385541 324.3356730837372 232.01799153588004\n",
      "R^2 score: 0.5379979645503135 0.371231242247938 0.4820681889591706 0.4776135484502063 0.3713434759235894 0.5502818956196709\n",
      "sq_error: 268.7905593996427 325.6111995353109 400.7300375534624 278.26431586824543 325.6087840567067 250.5993108205679\n",
      "R^2 score: 0.5057306762415703 0.40124523806953616 0.26311189978682226 0.4883097250978726 0.40124967980654846 0.5391819111122573\n",
      "sq_error: 160.0806728097826 224.5286399935059 145.70827431229426 171.83671406366054 224.4110569750852 120.88959060373422\n",
      "R^2 score: 0.7077186989071126 0.5900471813490029 0.7339603635561798 0.686254077519195 0.5902618688375498 0.7792752478481171\n",
      "sq_error: 262.6633561221485 247.98681482023056 164.31839942878378 210.33015637065637 248.01536350480626 172.8671370155083\n",
      "R^2 score: 0.5200846659083044 0.5469003486369794 0.6997719030034588 0.6157032760319987 0.5468481869967023 0.6841524031403441\n",
      "sq_error: 220.17719937158103 290.86209627666346 319.1850528338589 237.71418427755376 286.163474580827 207.15479443381946\n",
      "R^2 score: 0.5988010613377335 0.47000159573134526 0.41839252747651967 0.5668458009761077 0.4785632544449877 0.6225300171731784\n",
      "sq_error: 136.4744334600496 218.75634931140272 133.14124373267774 174.47330475832487 218.77841061281165 120.4074217390114\n",
      "R^2 score: 0.7468435790556611 0.5942128276595068 0.7530265567776893 0.6763566899445814 0.5941719045359263 0.7766474557191934\n",
      "sq_error: 210.0478971661738 273.7688876215321 226.7304085843357 199.76987843683563 269.20530349029116 195.80950963949243\n",
      "R^2 score: 0.6168268720877403 0.5005859025000722 0.5863943366147859 0.6355762175389146 0.5089108742310433 0.6428007930773384\n",
      "sq_error: 249.4738491786096 248.55124643162844 300.5787234986167 213.45416335276897 248.55800309494742 212.18882206277968\n",
      "R^2 score: 0.5424619049587318 0.544153969697074 0.4487349395044933 0.6085224499457178 0.5441415778937888 0.6108431013699249\n",
      "sq_error: 174.8194617650971 254.87311758464907 206.95047480133863 192.99511634264948 254.8691283737613 169.5008611884827\n",
      "R^2 score: 0.6698257409041704 0.5186317249104074 0.6091412306321136 0.6354981367396595 0.5186392591673828 0.6798707609899198\n",
      "sq_error: 303.65865519495384 307.99836371982053 315.3227483007267 258.3560518096172 302.7516125341911 246.9635028786761\n",
      "R^2 score: 0.44942001991034863 0.4415514589708227 0.42827121996648665 0.5315606276064948 0.45106462816227744 0.5522170760767051\n",
      "sq_error: 223.09924273709626 319.99505523933755 213.43415509745185 241.6701842133139 316.7871614605552 190.70773528426207\n",
      "R^2 score: 0.586768039614054 0.40729433964872286 0.6046700417169422 0.5523703139280312 0.41323610896471386 0.6467646848754816\n",
      "sq_error: 237.20662541057962 278.5630636303828 209.5493004158216 220.64535730243466 278.55149289103224 190.2634054934541\n",
      "R^2 score: 0.5560928164943056 0.4786986038402383 0.6078505834642374 0.5870854831976253 0.47872025725867595 0.6439421019096285\n",
      "sq_error: 314.8574255795789 238.6902506128095 410.0650425290973 219.04041073443364 238.73506342996885 235.02820588812037\n",
      "R^2 score: 0.4137078100682521 0.5555377819356145 0.2364228623279676 0.5921275102321428 0.5554543365327913 0.5623568309617375\n",
      "sq_error: 166.92964953738476 238.36644904141542 209.93695484119226 183.23424682315311 234.83521090596017 148.00122753112637\n",
      "R^2 score: 0.6772183905870885 0.5390854394958899 0.594057806107658 0.6456911923493001 0.5459135777669598 0.713819117514623\n",
      "sq_error: 255.4213830950884 311.38010458543926 236.83303903955849 273.7720719472508 311.37967133697794 243.68143759221806\n",
      "R^2 score: 0.5208501283678777 0.41587608941352183 0.5557203595135025 0.48642571917657185 0.4158769021526203 0.5428733173135514\n",
      "sq_error: 279.8120506638446 254.2270970501192 213.87080714696427 196.33164499279872 254.20613408561397 166.9147889207998\n",
      "R^2 score: 0.4814094781164553 0.528827430329128 0.6036218839365007 0.6361281438825958 0.5288662821036575 0.6906479642633061\n",
      "sq_error: 93.16316117573633 231.11070894123455 176.7220229553651 169.5932561653249 231.09544118594084 113.50789731921591\n",
      "R^2 score: 0.8243070448733073 0.564156873780646 0.6667264822580778 0.6801703595154049 0.5641856666748744 0.7859396604993677\n",
      "sq_error: 260.8992451469217 291.52216477336884 338.17231006395673 248.3055430590951 288.1324320234104 236.0925603561092\n",
      "R^2 score: 0.5139304667094101 0.4568782960814721 0.3699665292936264 0.5373932210488619 0.46319355320237443 0.5601466743951274\n",
      "sq_error: 202.52503231515527 230.35782991416133 276.6269822195535 189.2671357546293 230.34948884688504 175.16686750851233\n",
      "R^2 score: 0.6201253967036844 0.5679196381083906 0.48113295462564776 0.6449931285534254 0.5679352833823917 0.6714408903196358\n",
      "sq_error: 132.34040699045084 256.4126348557351 128.1960207508414 196.26657013970564 252.81985019235708 167.1508843480204\n",
      "R^2 score: 0.7563206903258922 0.5278656362461309 0.7639517774659202 0.6386130025488039 0.5344810555763952 0.6922239168247288\n",
      "sq_error: 259.9765146773137 271.7540867878604 290.86427033105514 212.3738384601758 271.7667104423407 201.33373930682907\n",
      "R^2 score: 0.5182850833557999 0.4964622191846074 0.46105263426886367 0.6064888937439867 0.49643882859998756 0.6269452816988722\n",
      "sq_error: 270.3041171039805 250.30386287710544 182.03605461162647 212.3811018619807 247.16054268389385 192.01422516200148\n",
      "R^2 score: 0.5063712938034082 0.5428957083161824 0.667566209934928 0.6121501601383035 0.5486360318331186 0.6493440996993824\n",
      "sq_error: 181.953262097929 254.20649495565937 217.10489720638375 214.17083931632396 254.22288776079262 186.515273430328\n",
      "R^2 score: 0.6708446392839087 0.540137782753961 0.6072549624598869 0.6125627039756436 0.5401081279974341 0.662591912905755\n",
      "sq_error: 228.33233200691197 253.2489190369565 279.3878797349657 197.49500154372785 253.25998957970688 191.82224697319506\n",
      "R^2 score: 0.5873459516750501 0.5423154016078894 0.49507571436677744 0.6430767767549692 0.5422953943481074 0.6533288734164853\n",
      "sq_error: 286.1920686298734 294.7876320349765 302.0220735251822 255.17892632549797 294.74900102739633 245.7217768199352\n",
      "R^2 score: 0.4711230760736609 0.4552386556742123 0.441869559947757 0.528434710815155 0.45531004496377236 0.545911324208247\n",
      "sq_error: 336.17824242897 290.9057817217575 302.16249719424883 244.01668844916975 286.7440627029591 230.65037450491678\n",
      "R^2 score: 0.38185775126222155 0.4651017484502963 0.4444036468560584 0.5513183023455615 0.4727540412765887 0.5758953936502771\n",
      "sq_error: 275.8446656239235 256.10461402673866 251.07244383934187 217.3358647026867 256.11432708413935 231.54201045795497\n",
      "R^2 score: 0.48563893602185293 0.5224477462250361 0.5318311156871717 0.5947389217905206 0.5224296345152164 0.5682490557306468\n",
      "sq_error: 308.443692162567 311.53527779738454 407.04515579264387 294.8375877206502 309.6570359197579 294.147429531773\n",
      "R^2 score: 0.4180656324481403 0.4122328014425325 0.23203627981344865 0.4437359897433002 0.41577644174687056 0.44503809699775276\n",
      "sq_error: 160.84135477825595 267.32658130385596 170.6961319903388 195.13937520684192 262.31449499127103 158.0733433268553\n",
      "R^2 score: 0.706191748548793 0.5116756164632046 0.6881900669221055 0.6435396935206981 0.5208311742341105 0.7112480638580874\n",
      "sq_error: 242.5897167397501 282.4605799118182 211.91577764931546 215.4867097106688 279.0478814444592 174.6858987615566\n",
      "R^2 score: 0.5495469149599712 0.47551264194775467 0.6065038654824835 0.599873174845128 0.48184951629508066 0.6756342228036423\n",
      "sq_error: 183.26536888666953 244.63801824596115 152.43371753244557 172.43084471903592 239.9479933038236 134.6081211023904\n",
      "R^2 score: 0.6558711014491807 0.5406278214259961 0.7137656304891609 0.6762157682609211 0.5494345759553352 0.7472378729687519\n",
      "sq_error: 212.236212134094 248.68644919338468 163.93396096148393 192.84281518117194 244.69291212870098 139.73044747377372\n",
      "R^2 score: 0.60234459332801 0.5340497736299239 0.6928458849788484 0.6386809426932778 0.5415322460579237 0.7381946871557615\n",
      "sq_error: 226.9539524729616 288.71249144971335 285.9240350420234 237.3761506260124 288.74249235954227 219.40483553928868\n",
      "R^2 score: 0.5844614485839361 0.471385410275992 0.4764909002827209 0.5653790529001427 0.4713304804786669 0.5982834115015576\n",
      "sq_error: 264.6132030214142 281.8112972865932 233.55155116762734 221.19316953404672 277.6343408621934 224.29798409039796\n",
      "R^2 score: 0.5074422554913687 0.4754292855247194 0.5652612040665668 0.5882654098798373 0.48320437842190445 0.582486029117532\n",
      "sq_error: 143.78711274638772 273.72578792645703 254.24583850555751 236.42142902210568 273.6894014842742 186.29653341549857\n",
      "R^2 score: 0.7358748483845579 0.49718814255175225 0.5329712144556389 0.5657131950639858 0.4972549814664138 0.657788523644752\n",
      "sq_error: 144.5900536407779 257.34740819338896 159.79293787246235 181.10931785538554 257.3498061394585 141.82926878568665\n",
      "R^2 score: 0.7240950857482125 0.5089329258641893 0.695085134062713 0.6544094869953252 0.5089283501337842 0.729363180541261\n",
      "sq_error: 198.56232387485923 233.68696287112905 182.4104642804076 172.0894788289177 233.72850902794897 138.1344854584381\n",
      "R^2 score: 0.6296251579782544 0.5641077810386433 0.659752940172336 0.6790044944526609 0.5640302857164265 0.7423401517919992\n",
      "sq_error: 109.25852056087915 241.6837443949081 98.93689230063187 179.52987937310525 237.25490359556173 130.10376328217995\n",
      "R^2 score: 0.7993964729764211 0.5562578433151213 0.8183474437840308 0.6703751174417991 0.5643893929683108 0.7611236756688142\n",
      "sq_error: 226.30491529509132 278.3819922560289 293.3584303165201 219.36721074774127 278.3505570225622 199.12670702297817\n",
      "R^2 score: 0.5757705793719359 0.47814729903649156 0.4500725856207902 0.5887759459446117 0.4782062272787859 0.6267186355993187\n",
      "sq_error: 230.8087530357736 269.51122946481047 275.2145817214614 201.49787409812475 269.4917701690197 179.24391373309558\n",
      "R^2 score: 0.5654584493037016 0.4925936471588108 0.4818559974762263 0.6206417758383903 0.4926302829989043 0.6625391056361685\n",
      "sq_error: 242.74585044740994 301.30010588232915 254.45327258961177 247.9856090425457 301.2850456712925 207.97649729689843\n",
      "R^2 score: 0.5421543076801845 0.43171446465728625 0.5200728064471161 0.5322715397681606 0.4317428698915501 0.6077331776603199\n",
      "sq_error: 247.67522928525148 283.85788778144394 311.0436462531506 239.10404895362058 283.84054310825707 215.79592234100633\n",
      "R^2 score: 0.5397963244098202 0.47256557032664004 0.4220518955902085 0.5557223768622431 0.4725977983470825 0.5990310499548297\n",
      "sq_error: 357.23294404820075 314.8702631072822 436.6755934112132 274.3448579966104 314.8645820302982 282.1251158199611\n",
      "R^2 score: 0.33708359795987364 0.41569593340656863 0.1896620452680321 0.49089884006671203 0.415706475768847 0.47646103244249627\n",
      "sq_error: 270.307919260068 278.30348663081236 305.4970469013088 228.09454520450504 278.3313866349016 214.12886568585577\n",
      "R^2 score: 0.5047753520385042 0.49012686505644243 0.4403061962849162 0.5821134609742618 0.49007575012891447 0.6076996470619583\n",
      "sq_error: 150.0590665448126 244.53247509548027 141.84126004899596 177.15756601683972 240.4303570866704 139.6844554300249\n",
      "R^2 score: 0.7212830461567463 0.5458098724477265 0.7365466489934555 0.6709507909956702 0.553429071087614 0.740552658275508\n",
      "sq_error: 219.03810365879275 293.44622645255447 315.91180545023184 257.3099949868512 293.45935535722657 226.0297983460193\n",
      "R^2 score: 0.6033630622265231 0.46862390279531985 0.42794295135306515 0.5340598427154231 0.4686001288105268 0.5907024140367061\n",
      "sq_error: 240.5274976322441 267.3306088774304 250.79549432531473 218.03462466552114 267.2977833304813 209.63588379275146\n",
      "R^2 score: 0.5500522824638493 0.49991249035542973 0.5308442429623543 0.5921290385596598 0.49997389614093035 0.60784031616027\n"
     ]
    }
   ],
   "source": [
    "for dataset_ind in range(datasets):\n",
    "    vb_laplace_exact_obj = VBLaplace(**ln_vb_params)\n",
    "    vb_laplace_approx_obj = VBApproxLaplace(**ln_vb_params)\n",
    "    vb_normal_obj = VBNormal(**ln_vb_params)\n",
    "    lasso_obj = LassoCV(**ln_lasso_params)\n",
    "    ridge_obj = RidgeCV(**ln_ridge_params)\n",
    "    ard_obj = ARDRegression(**ln_ard_params)\n",
    "    \n",
    "    # data generation\n",
    "    train_X = np.random.normal(size = (n, M))\n",
    "    train_Y = train_X @ true_w + np.random.normal(size = n)\n",
    "\n",
    "    lasso_obj.fit(train_X, train_Y)\n",
    "    ridge_obj.fit(train_X, train_Y)\n",
    "    ard_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_exact_obj.fit(train_X, train_Y)\n",
    "    vb_normal_obj.fit(train_X, train_Y)\n",
    "    vb_laplace_approx_obj.fit(train_X, train_Y)\n",
    "\n",
    "    test_X = np.random.normal(size = (N, M))\n",
    "    test_Y = test_X @ true_w + np.random.normal(size = N)\n",
    "    \n",
    "    ### evaluation by square error\n",
    "    sq_error_lasso[dataset_ind] = sq_error(test_X, test_Y, lasso_obj.coef_)\n",
    "    sq_error_ridge[dataset_ind] = sq_error(test_X, test_Y, ridge_obj.coef_)\n",
    "    sq_error_ard[dataset_ind] = sq_error(test_X, test_Y, ard_obj.coef_)\n",
    "    sq_error_vb_laplace_exact[dataset_ind] = sq_error(test_X, test_Y, vb_laplace_exact_obj.mean_)\n",
    "    sq_error_vb_normal[dataset_ind] = sq_error(test_X, test_Y, vb_normal_obj.mean_)\n",
    "    sq_error_vb_laplace_approx[dataset_ind] = sq_error(test_X, test_Y, vb_laplace_approx_obj.mean_)\n",
    "\n",
    "    print(\n",
    "        \"sq_error:\"\n",
    "        , sq_error_lasso[dataset_ind]\n",
    "        , sq_error_ridge[dataset_ind]\n",
    "        , sq_error_ard[dataset_ind]\n",
    "        , sq_error_vb_laplace_exact[dataset_ind]\n",
    "        , sq_error_vb_normal[dataset_ind]\n",
    "        , sq_error_vb_laplace_approx[dataset_ind]\n",
    "    )    \n",
    "    \n",
    "    ### evaluation by R^2 score\n",
    "    score_lasso[dataset_ind] = score_func(test_X, test_Y, lasso_obj.coef_)\n",
    "    score_ridge[dataset_ind] = score_func(test_X, test_Y, ridge_obj.coef_)\n",
    "    score_ard[dataset_ind] = score_func(test_X, test_Y, ard_obj.coef_)\n",
    "    score_vb_laplace_exact[dataset_ind] = score_func(test_X, test_Y, vb_laplace_exact_obj.mean_)\n",
    "    score_vb_normal[dataset_ind] = score_func(test_X, test_Y, vb_normal_obj.mean_)\n",
    "    score_vb_laplace_approx[dataset_ind] = score_func(test_X, test_Y, vb_laplace_approx_obj.mean_)\n",
    "    \n",
    "    print(\n",
    "        \"R^2 score:\"\n",
    "        , score_lasso[dataset_ind]\n",
    "        , score_ridge[dataset_ind]\n",
    "        , score_ard[dataset_ind]\n",
    "        , score_vb_laplace_exact[dataset_ind]\n",
    "        , score_vb_normal[dataset_ind]\n",
    "        , score_vb_laplace_approx[dataset_ind]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.42579850e-01, 2.58307681e+00, 3.04929324e+00, 4.69251805e-01,\n",
       "       8.65503650e-01, 2.39588821e+00, 1.81665592e+00, 3.22227545e-01,\n",
       "       7.81719592e-01, 8.70814160e-01, 7.59146840e-01, 1.09531229e+00,\n",
       "       6.63304506e-01, 1.23803751e-01, 3.66329669e-01, 9.55048759e-01,\n",
       "       6.18741613e-01, 1.36999754e+00, 1.80068829e+00, 6.30155411e+00,\n",
       "       1.11670344e+00, 5.17454343e-01, 1.27908422e+00, 1.51344126e-01,\n",
       "       2.13806304e+00, 2.27860240e+00, 2.41070991e-02, 4.57708486e-01,\n",
       "       2.30080778e+00, 4.50777373e-01, 1.24084154e+00, 1.52522300e+00,\n",
       "       2.12599545e+00, 7.01237508e-02, 8.21981334e-01, 3.46841699e-01,\n",
       "       2.99670279e-01, 5.89226640e+00, 8.00567606e-01, 1.00850448e+00,\n",
       "       1.13598164e+00, 1.39240392e+00, 9.79933249e-02, 1.33878390e-01,\n",
       "       1.38862960e+00, 1.40470931e-01, 1.19874958e+00, 1.37112526e-01,\n",
       "       1.78480001e+00, 9.66082280e-01, 1.18055679e+00, 1.92307299e+00,\n",
       "       1.08985184e+00, 9.85456676e-01, 3.59484722e-01, 8.05456099e-02,\n",
       "       1.60039764e+00, 1.42282801e+00, 8.57058102e-01, 6.38569922e-01,\n",
       "       1.35472481e+00, 1.70023248e+00, 9.85498579e-01, 1.07471724e+00,\n",
       "       6.02756385e-01, 5.89087542e-01, 9.41580893e-01, 1.00687723e+00,\n",
       "       1.18548309e+00, 1.09277015e+00, 1.15702703e+00, 1.03488572e+00,\n",
       "       1.41357004e+00, 5.97994351e-01, 5.09818602e-01, 1.22729885e+00,\n",
       "       2.83195015e+00, 1.30509161e+00, 1.34024777e+00, 8.17831254e-01,\n",
       "       1.67200410e+00, 2.73949639e+00, 1.78220467e+00, 2.84642103e-01,\n",
       "       4.23412051e-01, 1.13346912e-01, 1.03840411e+00, 1.24434665e+00,\n",
       "       1.38584123e+00, 4.20129099e-01, 7.36433850e-01, 7.25351703e-01,\n",
       "       2.40443495e-01, 7.75780078e-01, 8.22109057e-01, 1.57122136e+00,\n",
       "       1.33307953e+00, 9.14271261e-01, 1.29886169e+00, 5.17846243e-01,\n",
       "       2.92471218e+00, 8.74470509e-01, 7.78339090e-01, 8.49561897e-01,\n",
       "       1.01609878e-01, 5.02681176e-01, 1.41052940e+00, 6.99865293e-01,\n",
       "       9.37843482e-01, 6.09269456e-01, 2.46212084e-01, 1.09410406e+00,\n",
       "       1.20572914e+00, 2.60735086e-01, 1.16448108e-01, 6.63973600e-01,\n",
       "       1.29577662e+00, 1.77241792e+00, 2.99500643e-01, 4.23020176e-01,\n",
       "       3.22867877e-02, 1.10620481e+00, 8.75806735e-01, 3.78503443e+00,\n",
       "       7.38453761e-02, 1.12316413e+00, 1.56562914e-01, 1.67019164e+00,\n",
       "       2.67284356e+00, 2.90932445e-01, 3.47675317e+00, 1.99747740e+00,\n",
       "       3.67314280e+00, 1.21169945e+00, 1.96565725e+00, 6.02901564e-01,\n",
       "       1.04112148e+00, 4.55739648e-01, 5.03979515e-01, 6.78310674e-01,\n",
       "       1.84784997e-01, 1.12978664e+00, 1.13955691e+00, 8.28960963e-01,\n",
       "       1.30987108e+00, 1.46280260e+00, 7.32163125e-01, 9.21041512e-01,\n",
       "       1.53884448e+00, 1.11119057e+00, 9.92109494e-01, 5.34241665e-01,\n",
       "       8.18376382e-01, 7.65866715e-01, 1.05105926e+00, 1.77426284e+00,\n",
       "       4.77449702e-01, 1.26887398e+00, 1.12025450e+00, 2.54485686e+00,\n",
       "       1.66270345e+00, 3.34422998e+00, 4.29186028e+00, 3.07104617e-03,\n",
       "       9.75288119e-01, 2.99744666e+00, 2.88742039e+00, 8.82219185e-01,\n",
       "       2.35646817e+00, 1.19840208e+00, 7.33579738e-01, 1.08621497e+00,\n",
       "       2.09256416e+00, 1.17454499e-01, 8.22230545e-01, 9.47474500e-01,\n",
       "       5.49070087e-01, 1.16641180e+00, 1.08422898e+00, 8.20264643e-01,\n",
       "       5.49878175e+00, 4.29188478e+00, 4.14889972e-01, 1.19157155e+00,\n",
       "       1.94793077e+00, 9.84280433e-01, 1.42132416e+00, 2.88501173e+00,\n",
       "       6.09713826e-01, 2.11075266e+00, 5.40732309e-01, 7.85370871e-01,\n",
       "       2.42810958e-01, 1.15090589e+00, 1.21500154e+00, 1.00176882e+00,\n",
       "       1.37757533e+00, 1.25768476e+00, 5.21919629e-01, 3.03300358e+00])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(vb_laplace_exact_obj.mean_ - np.sqrt(np.diag(vb_laplace_exact_obj.sigma_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = vb_laplace_exact_obj.mean_ + 0.8 * np.sqrt(np.diag(vb_laplace_exact_obj.sigma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = vb_laplace_exact_obj.mean_ - 0.8 * np.sqrt(np.diag(vb_laplace_exact_obj.sigma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(((lower < 0) & (0 < upper)))[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(vb_laplace_exact_obj.mean_) < 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lasso_obj.coef_ < 0.001).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(true_w < 0.001).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229.2178187139233 270.9310271850848 236.02793215883284 216.86059372585152 269.37613375278215 188.90862899368614\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sq_error_lasso.mean()\n",
    "    , sq_error_ridge.mean()\n",
    "    , sq_error_ard.mean()\n",
    "    , sq_error_vb_laplace_exact.mean()\n",
    "    , sq_error_vb_normal.mean()\n",
    "    , sq_error_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5749632491163943 0.4975290123932801 0.5623307038489177 0.5978201577849914 0.5004077146598158 0.6496948673843996\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    score_lasso.mean()\n",
    "    , score_ridge.mean()\n",
    "    , score_ard.mean()\n",
    "    , score_vb_laplace_exact.mean()\n",
    "    , score_vb_normal.mean()\n",
    "    , score_vb_laplace_approx.mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        , -0.76668197,\n",
       "        0.07758316,  0.        , -0.0995576 ,  0.        , -0.90644613,\n",
       "        0.        ,  0.        , -1.16645995,  1.00565264, -1.27819984,\n",
       "        0.30094245, -0.627204  ,  3.38047157,  1.22344481,  0.0473449 ,\n",
       "       -0.03814966,  0.        ,  0.        ,  3.52029545,  0.        ,\n",
       "        4.81596502,  0.        , -3.25347577,  0.66002526,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.63380714,  1.33677451,\n",
       "        0.        , -2.69622796,  3.58475763,  0.        ,  0.        ,\n",
       "        2.71306942,  0.        ,  1.88162727, -2.59235379,  3.48865255,\n",
       "        0.        ,  0.        ,  0.        ,  2.00792993, -0.4410573 ,\n",
       "        0.        , -4.15620415,  3.9016001 ,  0.        ,  6.5176337 ,\n",
       "       -3.96303101, -0.03691128,  1.35713552,  2.36783035,  0.        ,\n",
       "        0.        ,  0.18762913, -1.26910508, -3.83069906,  0.26426108,\n",
       "       -1.0842188 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        2.82239462,  0.16265215,  0.        ,  0.        ,  0.        ,\n",
       "        1.42660064, -0.55960312, -1.35619478, -5.20937925,  0.        ,\n",
       "       -0.97513867,  0.        ,  5.61036017, -2.75649377, -4.37142083,\n",
       "        0.6528961 ,  3.65665585,  4.40974135, -0.18317878, -3.07988735,\n",
       "        0.        , -2.53854171,  3.27560309,  0.        ,  7.81317023,\n",
       "        0.        ,  0.        ,  0.        , -4.21542812,  0.        ,\n",
       "       -5.32304818,  0.        ,  0.        ,  1.46339651, -2.80157424,\n",
       "        2.40381311,  1.93661268,  0.        , -3.68530166,  3.68187137,\n",
       "        4.6779508 ,  1.30380009,  0.        ,  0.17820812,  0.        ,\n",
       "       -4.04242208,  0.        ,  0.        ,  0.        , -1.69246901,\n",
       "        1.35555417,  2.7963506 ,  0.        ,  3.07879094, -3.43986175,\n",
       "       -5.22595885,  0.39853712,  3.12602451, -4.18756991,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  4.31956641,\n",
       "       -1.51861904, -4.10136198,  0.30293722,  0.        ,  0.        ,\n",
       "        0.        , -0.21288762,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  2.77619219,  3.10719351,\n",
       "       -2.62922584,  1.34767249,  1.17694762,  0.        ,  0.82839278,\n",
       "        0.        , -2.43049864, -4.70204062,  0.31933329,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.37294018,\n",
       "        0.        ,  0.49227329,  1.88058534, -2.15501367,  0.        ,\n",
       "        2.51412901, -2.62329196,  1.88505711,  0.        , -1.44365597,\n",
       "        0.        , -5.9506191 ,  4.61010472, -0.3914984 , -2.56273853,\n",
       "        0.        ,  0.        , -0.03003618,  2.00666083, -1.11247555,\n",
       "        5.80470762, -0.75163024, -0.23380517,  0.67443324,  1.1577714 ,\n",
       "       -1.46410966,  0.        , -3.65760862, -1.67716493, -2.42723579,\n",
       "        0.        , -1.72682638, -0.84503449, -0.45390357,  0.        ,\n",
       "        0.        ,  0.        , -3.61775795, -1.11710953,  3.11547965,\n",
       "       -3.40428624,  1.72675508,  0.        , -1.09670842,  2.21402638,\n",
       "        0.        ,  5.68384374, 10.00605115,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -4.4211814 ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -1.12343038,  0.        ,  0.18522035,\n",
       "       -1.45337341,  0.        ,  2.88056761,  0.47835039,  1.22293896,\n",
       "        6.02282615, -0.55582293,  2.80719361, -9.04599777,  1.31709791,\n",
       "        0.        ,  1.41886036, -2.11526084,  1.31447898,  0.        ,\n",
       "       -1.88083653, -1.16022406,  0.        ,  0.        , -3.53824703,\n",
       "       -0.63372719,  0.        , -6.38107692,  5.22173563, -1.72092071,\n",
       "        1.34919695,  3.33451544,  2.68218189,  0.        , -9.42245829,\n",
       "        4.31844858,  0.        , -0.27071409, -1.75983284,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , -3.71381013,\n",
       "       -4.36134198,  0.        ,  2.86892206,  4.43305466,  0.        ,\n",
       "        0.        ,  3.6775742 ,  0.        ,  0.        ,  0.        ,\n",
       "        1.08341558, -3.30639853,  2.06305632,  0.33057913,  0.19251094,\n",
       "        0.        ,  0.        , -0.88649413,  0.93654874, -0.92907885,\n",
       "        0.        ,  1.98561399,  0.        , -6.21216341, -1.44129124,\n",
       "        0.        , -2.44364738,  0.        ,  0.        , -4.60931771,\n",
       "        0.        , -7.1060601 , -0.25450493,  3.80237406, -1.03990865,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.50845406,\n",
       "        1.43603562,  0.        , -1.20824397,  0.34298881,  0.        ,\n",
       "       -0.10126385,  2.32899934,  0.        ,  0.        ,  2.53418494,\n",
       "        1.09601969, -1.3079937 , -1.43857833,  1.69509419,  0.        ,\n",
       "       -0.32535721,  1.34677404,  0.        ,  1.6209045 ,  0.        ,\n",
       "        0.37218781,  0.10660404, -2.18739269, -0.21103329,  3.88906184,\n",
       "        0.14417489, -0.44632924,  0.        , -3.08581264,  0.        ,\n",
       "       -0.64647768,  0.        ,  0.        ,  0.        ,  3.45132807,\n",
       "       -5.00554243, -0.69960904, -1.49639685,  0.        ,  0.        ,\n",
       "        0.        ,  0.82544241, -1.59146572,  2.98871443,  3.62286903,\n",
       "        1.42762964,  0.        ,  0.        ,  2.47423043,  0.        ,\n",
       "        0.        , -3.93509534, -3.67117534, -1.66381531,  1.56373128,\n",
       "       -2.54003703,  1.59270721,  0.        , -3.34179223,  0.        ,\n",
       "        1.65598468, -0.63192153,  3.2586072 ,  3.79248979,  1.8805576 ,\n",
       "        0.        ,  0.        ,  0.67639555,  2.12813618,  0.        ,\n",
       "       -2.03734815, -0.92737418, -0.76446219,  0.26149847, -1.01734604,\n",
       "        0.        ,  0.        ,  0.        ,  2.90633058, -1.7841167 ,\n",
       "        0.        ,  2.43839142,  1.72382498,  0.91379309, -4.73625657,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.76208384,\n",
       "       -5.52170122, -5.29286887,  3.40864884,  1.99232504,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  5.62730881,  0.        ,\n",
       "        0.        , -2.27439354,  0.4710198 ,  0.        ,  2.47498796,\n",
       "        0.        , -0.08208131, -4.96373925, -0.44566027,  0.        ,\n",
       "       -6.48977714,  0.        ,  0.        ,  2.27450145, -3.93815903,\n",
       "        3.3400167 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.463294  ,  0.        , -0.97093426,\n",
       "        0.        ,  2.09674151,  2.34015509,  0.        ,  2.04765046,\n",
       "        0.        ,  2.79378918, -3.53025833,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.34513262,  1.83249431,  0.        ,  2.75072664, -0.09395582,\n",
       "        0.        , -4.52339131,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.13120524, -1.74165902,  0.        ,  2.79691941,\n",
       "        2.63991594,  0.        ,  3.2993635 , -2.01361589,  2.02896249,\n",
       "        1.14511249, -0.30690699,  2.8638261 ,  0.        , -1.90000553,\n",
       "        2.10753598,  1.25927173, -2.0796748 ,  0.        ,  0.8230681 ,\n",
       "        2.19885118,  2.00914115,  8.62446715,  0.        , -1.25440593,\n",
       "        2.36717472,  1.67806024,  0.45576057,  0.        ,  2.94290434,\n",
       "       -6.67368945,  4.84287936,  0.        , -1.54032161,  0.        ,\n",
       "       -1.45007199,  0.        ,  0.        ,  0.14619982,  1.24542242,\n",
       "       -1.1466085 ,  0.        ,  0.        , -0.87419234,  4.46233691,\n",
       "       -1.71233723, -5.01433667,  2.26989479,  3.50090393,  0.        ,\n",
       "        1.14726699,  0.        , -6.01328696,  1.50616649,  0.        ,\n",
       "        1.71264187,  0.        ,  1.61466992,  0.43339527,  0.        ,\n",
       "        0.        ,  0.04176741, -2.46692818, -1.69221917,  0.        ,\n",
       "        4.96165716,  5.70358511,  0.        ,  1.64405708,  3.47260936,\n",
       "       -4.14704621,  1.13520012,  4.72538745,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        , -0.72411832,  2.05994544,\n",
       "       -2.04054909, -5.93196356,  0.        , -6.38319172,  2.66130388,\n",
       "        0.54021669,  2.11793369, -5.40525212,  1.69551788,  0.        ,\n",
       "        0.        ,  1.63502311, -0.87789452, -1.26780838,  0.        ,\n",
       "       -1.69376272,  1.42150321,  0.75101169,  1.70050797,  0.        ,\n",
       "        6.76881923,  0.        , -1.72645458, -0.34222196,  0.        ,\n",
       "        0.        ,  0.        ,  4.20692684, -1.49838649, -0.42849111,\n",
       "        3.27441965,  0.        ,  0.        ,  1.33915726, -2.84127863,\n",
       "        0.        , -1.43255817,  0.        , -3.91065627,  0.        ,\n",
       "        3.28198124,  0.        ,  1.08150973, -0.74044771, -5.10018979,\n",
       "        0.98746237,  0.        ,  2.98754322, -3.93588581, -2.10669405,\n",
       "        0.        ,  0.        , -1.75450388,  0.80332304,  0.        ,\n",
       "        2.25687791,  0.        , -3.02195407, -0.34214784, -1.19599784,\n",
       "        0.        ,  0.        ,  1.20211888,  4.74596595, -3.36959436])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "+ We experimented the performance of the rigorously derived variational linear regression algorithm for the Laplace prior by comparing:\n",
    "    1. Ordinal optimized Lasso by cross-validation\n",
    "    2. Ordinal optimized Ridge by cross-validation\n",
    "    3. Variational Bayes linear regression for the normal prior\n",
    "    4. Bayesian ARD\n",
    "    5. Variational Bayes linear regression for the approximated Laplace prior.\n",
    "+ Results are as follows:\n",
    "    1. n > M with non-zero elements: ridge, vb for the normal prior gives the best performance, although vb for the Laplace prior gives better performance.\n",
    "    2. n > M with zero-elements: lasso, vb for the approximated Laplace gives the best performance. although vb for the Laplace prior also gives better performance.\n",
    "    3. M > n with zero-elements: results is similar with 1.\n",
    "    4. M > n with zero-elements: results is similar with 2.\n",
    "    5. M >> n, especially # of non-zero elements is larger than # of samples, vb for the Laplace prior gives the best performance.\n",
    "+ Summary of results:\n",
    "    + Derived algorithm can estimate every case, and # of features are extremely larger. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
